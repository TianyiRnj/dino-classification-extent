{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1SzyWjzjhqC",
        "outputId": "c4fcb015-4f8d-4f18-8050-b9653b821805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: setuptools in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch) (75.8.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (865.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.0/865.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m142.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, nvidia-cusparselt-cu12, mpmath, tzdata, triton, tqdm, sympy, pyparsing, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, fsspec, fonttools, filelock, cycler, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, contourpy, nvidia-cusolver-cu12, matplotlib, torch, torchvision\n",
            "Successfully installed MarkupSafe-3.0.2 contourpy-1.3.2 cycler-0.12.1 filelock-3.18.0 fonttools-4.57.0 fsspec-2025.3.2 jinja2-3.1.6 kiwisolver-1.4.8 matplotlib-3.10.1 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.5 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pandas-2.2.3 pillow-11.2.1 pyparsing-3.2.3 pytz-2025.2 sympy-1.13.3 torch-2.7.0 torchvision-0.22.0 tqdm-4.67.1 triton-3.3.0 tzdata-2025.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pandas numpy matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting nvidia-modelopt[all]\n",
            "  Downloading https://pypi.nvidia.com/nvidia-modelopt/nvidia_modelopt-0.27.1-py3-none-manylinux_2_28_x86_64.whl (658 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.2/658.2 kB\u001b[0m \u001b[31m144.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-modelopt-core==0.27.1 (from nvidia-modelopt[all])\n",
            "  Downloading https://pypi.nvidia.com/nvidia-modelopt-core/nvidia_modelopt_core-0.27.1-cp312-cp312-manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m201.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from nvidia-modelopt[all])\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy in ./anaconda3/envs/quant/lib/python3.12/site-packages (from nvidia-modelopt[all]) (2.2.5)\n",
            "Requirement already satisfied: packaging in ./anaconda3/envs/quant/lib/python3.12/site-packages (from nvidia-modelopt[all]) (25.0)\n",
            "Collecting pydantic>=2.0 (from nvidia-modelopt[all])\n",
            "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
            "Collecting rich (from nvidia-modelopt[all])\n",
            "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting scipy (from nvidia-modelopt[all])\n",
            "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: tqdm in ./anaconda3/envs/quant/lib/python3.12/site-packages (from nvidia-modelopt[all]) (4.67.1)\n",
            "Requirement already satisfied: setuptools in ./anaconda3/envs/quant/lib/python3.12/site-packages (from nvidia-modelopt[all]) (75.8.0)\n",
            "Collecting cppimport (from nvidia-modelopt[all])\n",
            "  Downloading cppimport-22.8.2.tar.gz (26 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting cupy-cuda12x (from nvidia-modelopt[all])\n",
            "  Downloading cupy_cuda12x-13.4.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting onnx (from nvidia-modelopt[all])\n",
            "  Downloading onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxconverter-common (from nvidia-modelopt[all])\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting onnx-graphsurgeon (from nvidia-modelopt[all])\n",
            "  Downloading https://pypi.nvidia.com/onnx-graphsurgeon/onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n",
            "Collecting onnxruntime-gpu~=1.20.1 (from nvidia-modelopt[all])\n",
            "  Downloading onnxruntime_gpu-1.20.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting pulp (from nvidia-modelopt[all])\n",
            "  Downloading pulp-3.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pynvml>=11.5.0 (from nvidia-modelopt[all])\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting regex (from nvidia-modelopt[all])\n",
            "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting safetensors (from nvidia-modelopt[all])\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: torch>=2.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from nvidia-modelopt[all]) (2.7.0)\n",
            "Collecting torchprofile>=0.0.4 (from nvidia-modelopt[all])\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\n",
            "Requirement already satisfied: torchvision in ./anaconda3/envs/quant/lib/python3.12/site-packages (from nvidia-modelopt[all]) (0.22.0)\n",
            "Collecting accelerate>=1.0.0 (from nvidia-modelopt[all])\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting datasets>=3.0.0 (from nvidia-modelopt[all])\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diffusers>=0.32.2 (from nvidia-modelopt[all])\n",
            "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting huggingface_hub>=0.24.0 (from nvidia-modelopt[all])\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting peft>=0.12.0 (from nvidia-modelopt[all])\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers<4.51.0,>=4.48.0 (from nvidia-modelopt[all])\n",
            "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: psutil in ./anaconda3/envs/quant/lib/python3.12/site-packages (from accelerate>=1.0.0->nvidia-modelopt[all]) (5.9.0)\n",
            "Collecting pyyaml (from accelerate>=1.0.0->nvidia-modelopt[all])\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: filelock in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (3.18.0)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets>=3.0.0->nvidia-modelopt[all]) (2.2.3)\n",
            "Collecting requests>=2.32.2 (from datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting xxhash (from datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: importlib-metadata in ./anaconda3/envs/quant/lib/python3.12/site-packages (from diffusers>=0.32.2->nvidia-modelopt[all]) (8.6.1)\n",
            "Requirement already satisfied: Pillow in ./anaconda3/envs/quant/lib/python3.12/site-packages (from diffusers>=0.32.2->nvidia-modelopt[all]) (11.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from huggingface_hub>=0.24.0->nvidia-modelopt[all]) (4.13.2)\n",
            "Collecting coloredlogs (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all])\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting protobuf (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all])\n",
            "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: sympy in ./anaconda3/envs/quant/lib/python3.12/site-packages (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (1.13.3)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->nvidia-modelopt[all])\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.1 (from pydantic>=2.0->nvidia-modelopt[all])\n",
            "  Downloading pydantic_core-2.33.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2.0->nvidia-modelopt[all])\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml>=11.5.0->nvidia-modelopt[all])\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: networkx in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from torch>=2.2->nvidia-modelopt[all]) (3.3.0)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<4.51.0,>=4.48.0->nvidia-modelopt[all])\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting mako (from cppimport->nvidia-modelopt[all])\n",
            "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pybind11 (from cppimport->nvidia-modelopt[all])\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x->nvidia-modelopt[all])\n",
            "  Downloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting protobuf (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all])\n",
            "  Downloading protobuf-3.20.2-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->nvidia-modelopt[all])\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from rich->nvidia-modelopt[all]) (2.19.1)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->nvidia-modelopt[all])\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets>=3.0.0->nvidia-modelopt[all])\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from sympy->onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu~=1.20.1->nvidia-modelopt[all])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from importlib-metadata->diffusers>=0.32.2->nvidia-modelopt[all]) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from jinja2->torch>=2.2->nvidia-modelopt[all]) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->nvidia-modelopt[all]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->nvidia-modelopt[all]) (1.17.0)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "Downloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Downloading onnxruntime_gpu-1.20.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
            "Downloading pydantic_core-2.33.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m143.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cupy_cuda12x-13.4.1-cp312-cp312-manylinux2014_x86_64.whl (105.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 MB\u001b[0m \u001b[31m141.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Downloading onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m152.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "Downloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
            "Downloading pulp-3.1.1-py3-none-any.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m171.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m167.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m150.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Downloading charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)\n",
            "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
            "Building wheels for collected packages: cppimport\n",
            "  Building wheel for cppimport (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for cppimport: filename=cppimport-22.8.2-py3-none-any.whl size=17736 sha256=1878507dc06962b748e0d7a0c624374bbd19336e403806581e5e70b31fa32671\n",
            "  Stored in directory: /home/ubuntu/.cache/pip/wheels/14/30/51/941b474cecac2b6d38a772e515f817b0619e0407ba786e1bd1\n",
            "Successfully built cppimport\n",
            "Installing collected packages: nvidia-ml-py, flatbuffers, fastrlock, xxhash, urllib3, typing-inspection, scipy, safetensors, regex, pyyaml, pynvml, pydantic-core, pybind11, pyarrow, pulp, protobuf, propcache, nvidia-modelopt-core, ninja, multidict, mdurl, mako, idna, humanfriendly, fsspec, frozenlist, dill, cupy-cuda12x, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, requests, pydantic, onnx, multiprocess, markdown-it-py, cppimport, coloredlogs, aiosignal, rich, onnxruntime-gpu, onnxconverter-common, onnx-graphsurgeon, huggingface_hub, aiohttp, tokenizers, nvidia-modelopt, diffusers, accelerate, transformers, torchprofile, datasets, peft\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "Successfully installed accelerate-1.6.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 attrs-25.3.0 certifi-2025.1.31 charset-normalizer-3.4.1 coloredlogs-15.0.1 cppimport-22.8.2 cupy-cuda12x-13.4.1 datasets-3.5.0 diffusers-0.33.1 dill-0.3.8 fastrlock-0.8.3 flatbuffers-25.2.10 frozenlist-1.6.0 fsspec-2024.12.0 huggingface_hub-0.30.2 humanfriendly-10.0 idna-3.10 mako-1.3.10 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.4.3 multiprocess-0.70.16 ninja-1.11.1.4 nvidia-ml-py-12.570.86 nvidia-modelopt-0.27.1 nvidia-modelopt-core-0.27.1 onnx-1.17.0 onnx-graphsurgeon-0.5.8 onnxconverter-common-1.14.0 onnxruntime-gpu-1.20.2 peft-0.15.2 propcache-0.3.1 protobuf-3.20.2 pulp-3.1.1 pyarrow-19.0.1 pybind11-2.13.6 pydantic-2.11.3 pydantic-core-2.33.1 pynvml-12.0.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 rich-14.0.0 safetensors-0.5.3 scipy-1.15.2 tokenizers-0.21.1 torchprofile-0.0.4 transformers-4.50.3 typing-inspection-0.4.0 urllib3-2.4.0 xxhash-3.5.0 yarl-1.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install \"nvidia-modelopt[all]\" -U --extra-index-url https://pypi.nvidia.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5yHq_0kUnEkA"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zruaxu6jlhUQ",
        "outputId": "b487b01d-1bb1-432c-df9e-31f5d2a3623e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in ./anaconda3/envs/quant/lib/python3.12/site-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (2.2.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (3.11.18)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35Kcl-Jj_x1m",
        "outputId": "6518c1e3-8d9a-4281-d156-fe1eaff9fabd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-10.9.0.34.tar.gz (40 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tensorrt_cu12==10.9.0.34 (from tensorrt)\n",
            "  Downloading tensorrt_cu12-10.9.0.34.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tensorrt_cu12_libs==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
            "  Downloading tensorrt_cu12_libs-10.9.0.34.tar.gz (704 bytes)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tensorrt_cu12_bindings==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
            "  Downloading tensorrt_cu12_bindings-10.9.0.34-cp312-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from tensorrt_cu12_libs==10.9.0.34->tensorrt_cu12==10.9.0.34->tensorrt) (12.6.77)\n",
            "Downloading tensorrt_cu12_bindings-10.9.0.34-cp312-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for tensorrt: filename=tensorrt-10.9.0.34-py2.py3-none-any.whl size=46692 sha256=527f74305728c38ba1be288a588e2e2c2483068b8f24934409d2ea985cd5e7cb\n",
            "  Stored in directory: /home/ubuntu/.cache/pip/wheels/91/8d/04/64b9c236fa5deedc1b428601cc656805c0f8c823c68e48fd7e\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.9.0.34-py2.py3-none-any.whl size=17539 sha256=6117621d58e2f067c137617be3810633bf703864f29997093829af317ceaef1a\n",
            "  Stored in directory: /home/ubuntu/.cache/pip/wheels/bf/0e/f8/4e1ba893f27864bf15257740bdfa008945bde1b20a6b996fb4\n",
            "  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.9.0.34-py2.py3-none-manylinux_2_28_x86_64.whl size=3103291777 sha256=4a82f0bda2874596f202f6edc8dae99b86a3c4ec2fa142a9c847c4d3a57864a0\n",
            "  Stored in directory: /home/ubuntu/.cache/pip/wheels/af/63/d0/87d2c2a0bc94744ec9b391ee7c31f0cbc8053025a39f6cc5af\n",
            "Successfully built tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
            "Installing collected packages: tensorrt_cu12_bindings, tensorrt_cu12_libs, tensorrt_cu12, tensorrt\n",
            "Successfully installed tensorrt-10.9.0.34 tensorrt_cu12-10.9.0.34 tensorrt_cu12_bindings-10.9.0.34 tensorrt_cu12_libs-10.9.0.34\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install --upgrade tensorrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73297 sha256=7b5021a7d15aba444b5bb686d8571e53245c408417920482bdc967fd0515b11a\n",
            "  Stored in directory: /home/ubuntu/.cache/pip/wheels/6f/90/b4/bad113af4a919722b50a431481ea605c074772aab4d7d6072b\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.7.4.2\n",
            "    Uninstalling kaggle-1.7.4.2:\n",
            "      Successfully uninstalled kaggle-1.7.4.2\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir .kaggle\n",
        "\n",
        "with open(\".kaggle/kaggle.json\", \"w+\") as f:\n",
        "\n",
        "    f.write('{\"username\":\"furixiang\",\"key\":\"3ce49a8fe9150f81b4aad68d3b3b562b\"}') # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 .kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z6HP5mVj6Kc",
        "outputId": "0dfffdea-1a15-42a2-85d4-00b780977dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading places365.zip to /home/ubuntu\n",
            "100%|██████████████████████████████████████▉| 23.5G/23.5G [03:08<00:00, 201MB/s]\n",
            "100%|███████████████████████████████████████| 23.5G/23.5G [03:08<00:00, 134MB/s]\n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "!kaggle datasets download benjaminkz/places365\n",
        "!unzip -q places365.zip -d places365\n",
        "!rm places365.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfBncMXtiC75",
        "outputId": "f944e445-5eab-46d2-c1b6-e93252baf6ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in ./anaconda3/envs/quant/lib/python3.12/site-packages (2025.1)\n",
            "Requirement already satisfied: onnx in ./anaconda3/envs/quant/lib/python3.12/site-packages (1.17.0)\n",
            "Requirement already satisfied: onnxsim in ./anaconda3/envs/quant/lib/python3.12/site-packages (0.4.36)\n",
            "Requirement already satisfied: torchinfo in ./anaconda3/envs/quant/lib/python3.12/site-packages (1.8.0)\n",
            "Requirement already satisfied: pytools>=2011.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pycuda) (2025.1.2)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pycuda) (4.3.7)\n",
            "Requirement already satisfied: mako in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pycuda) (1.3.10)\n",
            "Requirement already satisfied: numpy>=1.20 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from onnx) (2.2.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from onnx) (3.20.2)\n",
            "Requirement already satisfied: rich in ./anaconda3/envs/quant/lib/python3.12/site-packages (from onnxsim) (14.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from pytools>=2011.2->pycuda) (4.13.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from mako->pycuda) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from rich->onnxsim) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/envs/quant/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda onnx onnxsim torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uvIBd2bsegY4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from typing import Literal, Tuple, Dict, List, Optional\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "vcgQRMYhiHPn",
        "outputId": "618057be-b7fc-4b66-c296-b6f293468008"
      },
      "outputs": [],
      "source": [
        "# TensorRT and CUDA\n",
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit  # Initializes CUDA context\n",
        "\n",
        "import onnx\n",
        "from onnxsim import simplify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfIr73lyeh3A"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4oYEH2aBj7xD"
      },
      "outputs": [],
      "source": [
        "class Places365Dataset(Dataset):\n",
        "    \"\"\"Dataset built from the official train/val text files.\n",
        "\n",
        "    Each line in the list file is a relative POSIX path, e.g.::\n",
        "        train/field-cultivated/0000516.jpg\n",
        "    The label is the directory name after the first component (train|val).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        list_file: str,\n",
        "        transform: Optional[transforms.Compose] = None,\n",
        "        class_to_idx: Optional[Dict[str, int]] = None,\n",
        "    ) -> None:\n",
        "        self.root: str = os.path.abspath(root)\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(list_file, \"r\") as f:\n",
        "            self.image_paths: List[str] = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "        if class_to_idx is None:\n",
        "            classes = sorted({self._extract_label(p) for p in self.image_paths})\n",
        "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "        else:\n",
        "            self.class_to_idx = class_to_idx\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_label(rel_path: str) -> str:\n",
        "        parts = rel_path.split(\"/\", 2)\n",
        "        if parts[0] in {\"train\", \"val\"}:\n",
        "            return parts[1]\n",
        "        return parts[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rel_path = self.image_paths[idx]\n",
        "        img_path = os.path.join(self.root, *rel_path.split(\"/\"))\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        label_name = self._extract_label(rel_path)\n",
        "        target = self.class_to_idx[label_name]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fshz4BxQj95f",
        "outputId": "aaedbacb-3906-4c13-9900-a1bfe62a6e6b"
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(data_root: str, batch_size: int = 64, num_workers: int = 4):\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    val_tf = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_list = os.path.join(data_root, \"train.txt\")\n",
        "    val_list = os.path.join(data_root, \"val.txt\")\n",
        "    if not os.path.exists(train_list) or not os.path.exists(val_list):\n",
        "        raise FileNotFoundError(\"train.txt / val.txt not found – check dataset integrity\")\n",
        "\n",
        "    train_ds = Places365Dataset(data_root, train_list, transform=train_tf)\n",
        "    val_ds = Places365Dataset(data_root, val_list, transform=val_tf, class_to_idx=train_ds.class_to_idx)\n",
        "\n",
        "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    return train_dl, val_dl, list(train_ds.class_to_idx.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIG4o9GAfVYF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYjSSyvtj_G6",
        "outputId": "9d037416-477c-4398-feae-883351f863a5"
      },
      "outputs": [],
      "source": [
        "class DINOv2Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=8, model_name='dinov2_vitl14', hidden_dim=512, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.dinov2 = torch.hub.load('facebookresearch/dinov2', model_name)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.dinov2.embed_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        for param in self.dinov2.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get all image features (batch_size, num_patches, embed_dim)\n",
        "        features = self.dinov2(x)\n",
        "\n",
        "        # Handle different output formats:\n",
        "        if features.dim() == 3:  # Standard case with spatial dimensions\n",
        "            cls_token = features[:, 0, :]  # Extract [CLS] token\n",
        "        else:  # Fallback for 2D output\n",
        "            cls_token = features\n",
        "\n",
        "        return self.classifier(cls_token)\n",
        "\n",
        "# model = DINOv2Classifier().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xm-d6ERJkBZx"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dl, val_dl, device, *, epochs: int, lr: float, ckpt_dir: str, save_freq: int, run=None):\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
        "    best_acc = 0.0\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        loss_sum, seen = 0.0, 0\n",
        "        train_loop = tqdm(train_dl, desc=f'Epoch {ep+1}/{epochs} [Train]', leave=True)\n",
        "        for x, y in train_loop:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            optim.zero_grad(set_to_none=True)\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            loss_sum += loss.item() * x.size(0)\n",
        "            seen += x.size(0)\n",
        "            avg_loss = loss_sum / seen\n",
        "            train_loop.set_postfix(loss=f\"{avg_loss:.4f}\", lr=f\"{sched.get_last_lr()[0]:.2e}\")\n",
        "        sched.step()\n",
        "        train_loss = loss_sum / len(train_dl)\n",
        "        # ---- validation ----\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        val_loop = tqdm(val_dl, desc=f'Epoch {ep+1}/{epochs} [Val]', leave=True)\n",
        "        with torch.inference_mode():\n",
        "            for x, y in val_loop:\n",
        "                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "                pred = model(x).argmax(1)\n",
        "                correct += (pred == y).sum().item()\n",
        "        val_acc = correct / len(val_dl.dataset)\n",
        "        lr_now = sched.get_last_lr()[0]\n",
        "        print(f\"Epoch {ep}/{epochs} | loss {train_loss:.4f} | val_acc {val_acc:.4f} | lr {lr_now:.2e}\")\n",
        "        if run:\n",
        "            run.log({\"epoch\": ep, \"train_loss\": train_loss, \"val_acc\": val_acc, \"lr\": lr_now})\n",
        "        # ---- checkpointing ----\n",
        "        if ep % save_freq == 0:\n",
        "            path = os.path.join(ckpt_dir, f\"epoch_{ep}.pth\")\n",
        "            torch.save(model.state_dict(), path)\n",
        "            if run:\n",
        "                run.save(path)\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_path = os.path.join(ckpt_dir, \"best.pth\")\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "            if run:\n",
        "                run.save(best_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8efHFigmkCZL",
        "outputId": "bb2e3ea8-6d71-4ec3-cd4c-07f417bef887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 1803460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/ubuntu/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
              "==========================================================================================================================================================================\n",
              "DINOv2Classifier                              [128, 3, 224, 224]        [128, 365]                --                        --                        --\n",
              "├─DinoVisionTransformer: 1-1                  [128, 3, 224, 224]        [128, 384]                526,848                   --                        --\n",
              "│    └─PatchEmbed: 2-1                        [128, 3, 224, 224]        [128, 256, 384]           --                        --                        --\n",
              "│    │    └─Conv2d: 3-1                       [128, 3, 224, 224]        [128, 384, 16, 16]        (226,176)                 [14, 14]                  7,411,335,168\n",
              "│    │    └─Identity: 3-2                     [128, 256, 384]           [128, 256, 384]           --                        --                        --\n",
              "│    └─ModuleList: 2-2                        --                        --                        --                        --                        --\n",
              "│    │    └─NestedTensorBlock: 3-3            [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-4            [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-5            [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-6            [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-7            [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-8            [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-9            [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-10           [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-11           [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-12           [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-13           [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    │    └─NestedTensorBlock: 3-14           [128, 257, 384]           [128, 257, 384]           (1,775,232)               --                        227,131,392\n",
              "│    └─LayerNorm: 2-3                         [128, 257, 384]           [128, 257, 384]           (768)                     --                        98,304\n",
              "│    └─Identity: 2-4                          [128, 384]                [128, 384]                --                        --                        --\n",
              "├─Sequential: 1-2                             [128, 384]                [128, 365]                --                        --                        --\n",
              "│    └─Linear: 2-5                            [128, 384]                [128, 512]                197,120                   --                        25,231,360\n",
              "│    └─GELU: 2-6                              [128, 512]                [128, 512]                --                        --                        --\n",
              "│    └─Dropout: 2-7                           [128, 512]                [128, 512]                --                        --                        --\n",
              "│    └─Linear: 2-8                            [128, 512]                [128, 365]                187,245                   --                        23,967,360\n",
              "==========================================================================================================================================================================\n",
              "Total params: 22,440,941\n",
              "Trainable params: 384,365\n",
              "Non-trainable params: 22,056,576\n",
              "Total mult-adds (Units.GIGABYTES): 10.19\n",
              "==========================================================================================================================================================================\n",
              "Input size (MB): 77.07\n",
              "Forward/backward pass size (MB): 15967.43\n",
              "Params size (MB): 87.66\n",
              "Estimated Total Size (MB): 16132.16\n",
              "=========================================================================================================================================================================="
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 128\n",
        "lr = 1e-4\n",
        "epochs = 10\n",
        "ckpt_dir = \"checkpoints\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dl, val_dl, class_names = get_dataloaders(\"places365\", batch_size=batch_size, num_workers=4)\n",
        "print(f\"Train dataset size: {len(train_dl.dataset)}\")\n",
        "model = DINOv2Classifier(num_classes=len(class_names), model_name='dinov2_vits14').to(device)\n",
        "input_shape = (batch_size, 3, 224, 224)\n",
        "summary(model, (input_shape), device=device, col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]:   4%|▍         | 584/14090 [01:39<37:45,  5.96it/s, loss=4.2400, lr=1.00e-04]"
          ]
        }
      ],
      "source": [
        "train(\n",
        "    model,\n",
        "    train_dl,\n",
        "    val_dl,\n",
        "    device,\n",
        "    epochs=10,\n",
        "    lr=1e-4,\n",
        "    ckpt_dir=\"checkpoints\",\n",
        "    save_freq=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a0i-1GuoD_D",
        "outputId": "fe9dd3ab-c59b-487a-e5ff-e8de71108a63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"checkpoints/best.pth\"))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OhxD4SykFKT",
        "outputId": "fefa0844-5983-4454-a61a-410385334996"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTesting:   0%|          | 0/60 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Testing: 100%|██████████| 60/60 [03:14<00:00,  3.24s/it, acc=0.7158]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Test Accuracy: 0.7158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Step 9: Final Evaluation ---\n",
        "model.eval()\n",
        "correct = 0\n",
        "val_loop = tqdm(val_dl, desc=f'[Final Val]', leave=True)\n",
        "with torch.inference_mode():\n",
        "    for x, y in val_loop:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "        pred = model(x).argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "val_acc = correct / len(val_dl.dataset)\n",
        "print(f\"Final validation accuracy: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import modelopt.torch.quantization as mtq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoQG-f29ZNuq",
        "outputId": "acbbce35-62c4-401f-a6c2-adba7ba52364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 297 quantizers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smoothed 98 modules\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Setup the model\n",
        "model = model.to(device)\n",
        "\n",
        "# Select quantization config\n",
        "config = mtq.INT8_SMOOTHQUANT_CFG\n",
        "\n",
        "# Quantization need calibration data. Setup calibration data loader\n",
        "# An example of creating a calibration data loader looks like the following:\n",
        "data_loader = train_dl\n",
        "\n",
        "\n",
        "# Define forward_loop. Please wrap the data loader in the forward_loop\n",
        "def forward_loop(model, limit = 1000):\n",
        "    iterations = 0\n",
        "    for images, labels in data_loader:\n",
        "        images = images.to(device)\n",
        "        model(images)\n",
        "        iterations += 1\n",
        "        if iterations >= limit:\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "# Quantize the model and perform calibration (PTQ)\n",
        "model_q = mtq.quantize(model, config, forward_loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XzOSSO5pwUB",
        "outputId": "8b446bf9-ccf2-4231-ea41-79a07a51063a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dinov2.patch_embed.proj.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=2.6400 calibrator=MaxCalibrator quant)\n",
            "dinov2.patch_embed.proj.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.patch_embed.proj.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0009, 0.0533](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.0.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0265, 4.8921](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.0.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0056, 0.3294](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.0.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.3914, 4.7904](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.0.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1056, 0.9492](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.1.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0252, 5.3203](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.1.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0079, 0.2145](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.1.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.2909, 5.2399](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.1.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0954, 0.7323](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.2.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0900, 3.1656](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.2.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0250, 0.2615](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.2.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1971, 3.2735](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.2.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1119, 0.7713](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.3.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0925, 2.0630](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.3.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0222, 0.2263](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.3.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.2195, 3.0800](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.3.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0926, 0.6086](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.4.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0946, 4.1730](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.4.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0173, 0.2961](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.4.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1580, 2.9996](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.4.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0646, 0.9352](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.5.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1099, 2.9456](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.5.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0151, 0.2812](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.5.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.2183, 2.5138](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.5.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0808, 0.7622](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.6.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1133, 3.2478](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.6.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0344, 0.5652](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.6.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1764, 1.8543](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.6.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0595, 0.6995](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.7.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1234, 3.3640](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.7.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0121, 0.2502](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.7.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1822, 1.6025](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.7.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0932, 0.5152](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.8.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1375, 4.4046](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.8.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0588, 0.5255](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.8.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1900, 1.2645](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.8.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0844, 0.4658](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.9.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1233, 4.4373](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.9.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0269, 0.2712](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.9.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1813, 1.6362](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.9.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1010, 1.3708](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.10.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1531, 3.5117](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.10.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0789, 0.2774](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.10.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1908, 6.6519](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.10.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1114, 0.7457](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.11.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1692, 2.8061](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.11.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0301, 0.2772](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.11.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1978, 2.2874](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.11.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1079, 0.7879](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.12.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1752, 2.7308](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.12.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0680, 0.3413](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.12.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2049, 3.9651](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.12.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1173, 1.4021](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.13.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1775, 4.3949](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.13.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0646, 0.3262](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.13.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1822, 14.0361](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.13.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1157, 0.5770](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.14.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1846, 3.2756](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.14.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0671, 0.2912](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.14.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1954, 3.2231](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.14.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1142, 0.5524](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.15.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1668, 4.1785](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.15.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0572, 0.4331](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.15.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1977, 2.5038](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.15.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1130, 0.4506](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.16.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1799, 4.0977](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.16.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0752, 1.0027](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.16.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1987, 3.6106](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.16.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1186, 0.5038](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.17.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1868, 3.7394](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.17.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0650, 0.8045](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.17.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2018, 4.6631](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.17.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1387, 10.4285](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.18.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1755, 4.2419](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.18.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0609, 0.6017](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.18.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2024, 8.9207](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.18.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1271, 14.7380](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.19.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1960, 4.4417](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.19.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0615, 0.4219](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.19.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2459, 8.5032](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.19.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1279, 6.3941](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.20.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.2189, 4.9504](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.20.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0640, 0.3872](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.20.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2535, 2.1648](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.20.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1259, 0.8512](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.21.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.2357, 4.0221](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.21.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0621, 1.1703](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.21.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2738, 3.0892](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.21.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1765, 1.0567](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.22.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.2436, 4.0446](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.22.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0596, 0.9389](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.22.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2909, 3.2084](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.22.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2100, 3.3324](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.23.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.2111, 4.1870](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.23.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0264, 1.5511](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.23.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2602, 6.9990](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.23.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0363, 19.1528](1024) calibrator=MaxCalibrator quant)\n",
            "classifier.0.input_quantizer                                                     TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "classifier.0.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "classifier.0.weight_quantizer                                                    TensorQuantizer(8 bit fake axis=0 amax=[0.1939, 0.4108](512) calibrator=MaxCalibrator quant)\n",
            "classifier.3.input_quantizer                                                     TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "classifier.3.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "classifier.3.weight_quantizer                                                    TensorQuantizer(8 bit fake axis=0 amax=[0.3838, 0.6763](8) calibrator=MaxCalibrator quant)\n",
            "297 TensorQuantizers found in model\n"
          ]
        }
      ],
      "source": [
        "mtq.print_quant_summary(model_q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZso4le5p-dE",
        "outputId": "8432fca1-6331-4b4e-f74c-f9946b674cbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTesting:   0%|          | 0/60 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Testing: 100%|██████████| 60/60 [03:13<00:00,  3.23s/it, acc=0.6721]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Test Accuracy: 0.6721\n"
          ]
        }
      ],
      "source": [
        "# Evaluated quantized model\n",
        "model_q = model_q.to(device)\n",
        "model_q.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "test_loop = tqdm(val_dl, desc='Testing', leave=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_q(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loop.set_postfix({'acc': f\"{test_correct/test_total:.4f}\"})\n",
        "\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPJkCwaTveqJ"
      },
      "outputs": [],
      "source": [
        "torch.save(model_q.state_dict(), 'quantized_dinov2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNp9Tyd0qbdI"
      },
      "outputs": [],
      "source": [
        "train(\n",
        "    model_q,\n",
        "    train_dl,\n",
        "    val_dl,\n",
        "    device,\n",
        "    epochs=10,\n",
        "    lr=1e-4,\n",
        "    ckpt_dir=\"checkpoints\",\n",
        "    save_freq=1\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "quant",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
