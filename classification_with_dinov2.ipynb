{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1SzyWjzjhqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb324c0b-2474-4e42-82e4-be40e00a4421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pandas numpy matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo --quiet"
      ],
      "metadata": {
        "id": "5yHq_0kUnEkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zruaxu6jlhUQ",
        "outputId": "bb13867d-04b7-4e65-d178-b16b7cca6300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.4.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --upgrade tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35Kcl-Jj_x1m",
        "outputId": "28a1f197-b4c8-4ca4-b8b9-9fb95e6ec07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-10.9.0.34.tar.gz (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12==10.9.0.34 (from tensorrt)\n",
            "  Downloading tensorrt_cu12-10.9.0.34.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_libs==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
            "  Downloading tensorrt_cu12_libs-10.9.0.34.tar.gz (704 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_bindings==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
            "  Downloading tensorrt_cu12_bindings-10.9.0.34-cp310-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt_cu12_libs==10.9.0.34->tensorrt_cu12==10.9.0.34->tensorrt) (12.6.77)\n",
            "Downloading tensorrt_cu12_bindings-10.9.0.34-cp310-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.9.0.34-py2.py3-none-any.whl size=46629 sha256=4ed0ee2e4e903bd9628f7482ffc5bc253e5c88aacbed7434e505589d47520f38\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/d7/3c/0e36cb8283a240ff39eeb4979199490cfeca25700fea039be0\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.9.0.34-py2.py3-none-any.whl size=17465 sha256=3a681b5fe1dc5d75fc76dfccff90ac96f818078707b2e625be26193546430394\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/0b/b3/cf89d2bb4bb66edec91708b0b785f811b3214d25ac949ba1b7\n",
            "  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.9.0.34-py2.py3-none-manylinux_2_28_x86_64.whl size=3103291777 sha256=4a82f0bda2874596f202f6edc8dae99b86a3c4ec2fa142a9c847c4d3a57864a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/92/68/0ca0823d8295b9b90a309e0cd95d8c183315286ecbd764bce3\n",
            "Successfully built tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
            "Installing collected packages: tensorrt_cu12_bindings, tensorrt_cu12_libs, tensorrt_cu12, tensorrt\n",
            "Successfully installed tensorrt-10.9.0.34 tensorrt_cu12-10.9.0.34 tensorrt_cu12_bindings-10.9.0.34 tensorrt_cu12_libs-10.9.0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "!kaggle datasets download andrewmvd/isic-2019\n",
        "!unzip -q isic-2019.zip"
      ],
      "metadata": {
        "id": "7z6HP5mVj6Kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f29fe3-e848-4a66-f2c7-7b99e229118b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/isic-2019\n",
            "License(s): Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
            "Downloading isic-2019.zip to /content\n",
            "100% 9.07G/9.10G [01:03<00:00, 199MB/s]\n",
            "100% 9.10G/9.10G [01:03<00:00, 154MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda onnx onnxsim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfBncMXtiC75",
        "outputId": "d5dcf182-4072-4518-ce9e-0d5eba7f2c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim) (13.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytools-2025.1.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1-cp310-cp310-linux_x86_64.whl size=660661 sha256=9bc3117f15c4465fa2efa0af50db58bd41e303b9bcdd300f1ed38e1ef8aa7c78\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/53/5f/f5f184c26b7cc503acb77f3456531a6e1fac0ce30c774b9d82\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, onnx, mako, pycuda, onnxsim\n",
            "Successfully installed mako-1.3.9 onnx-1.17.0 onnxsim-0.4.36 pycuda-2025.1 pytools-2025.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "uvIBd2bsegY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorRT and CUDA\n",
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit  # Initializes CUDA context\n",
        "\n",
        "import onnx\n",
        "from onnxsim import simplify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "vcgQRMYhiHPn",
        "outputId": "618057be-b7fc-4b66-c296-b6f293468008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mInstalling onnxruntime by `/usr/bin/python3 -m pip install onnxruntime`, please wait for a moment..\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Installing onnxruntime by `/usr/bin/python3 -m pip install onnxruntime`, please wait for a moment..</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Organize Data ---\n",
        "# Load metadata\n",
        "train_meta = pd.read_csv('ISIC_2019_Training_GroundTruth.csv')\n",
        "train_meta['image'] = train_meta['image'] + '.jpg'\n",
        "\n",
        "# Convert one-hot encoding to class labels\n",
        "classes = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n",
        "train_meta['label'] = train_meta[classes].idxmax(axis=1)\n",
        "label_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n"
      ],
      "metadata": {
        "id": "OfIr73lyeh3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(train_meta, test_size=0.3,\n",
        "                                    stratify=train_meta['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5,\n",
        "                                  stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "# --- Step 3: Define Dataset Class ---\n",
        "class ISIC2019Dataset(Dataset):\n",
        "    def __init__(self, df, img_dir='ISIC_2019_Training_Input/ISIC_2019_Training_Input', transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.label_to_idx = label_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.df.iloc[idx]['image'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.label_to_idx[self.df.iloc[idx]['label']]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "4oYEH2aBj7xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Data Transforms and Loaders ---\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create datasets and loaders\n",
        "batch_size = 64\n",
        "train_dataset = ISIC2019Dataset(train_df, transform=train_transform)\n",
        "val_dataset = ISIC2019Dataset(val_df, transform=val_transform)\n",
        "test_dataset = ISIC2019Dataset(test_df, transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "Fshz4BxQj95f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Model Setup ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- Step 5: Handle Class Imbalance ---\n",
        "train_labels = [label for _, label in train_dataset]\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
      ],
      "metadata": {
        "id": "zIG4o9GAfVYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DINOv2Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super().__init__()\n",
        "        self.dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.dinov2.embed_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "        for param in self.dinov2.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get all image features (batch_size, num_patches, embed_dim)\n",
        "        features = self.dinov2(x)\n",
        "\n",
        "        # Handle different output formats:\n",
        "        if features.dim() == 3:  # Standard case with spatial dimensions\n",
        "            cls_token = features[:, 0, :]  # Extract [CLS] token\n",
        "        else:  # Fallback for 2D output\n",
        "            cls_token = features\n",
        "\n",
        "        return self.classifier(cls_token)\n",
        "\n",
        "model = DINOv2Classifier().to(device)"
      ],
      "metadata": {
        "id": "RYjSSyvtj_G6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90b0d36-0632-45da-acf6-7ec47c871dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth\n",
            "100%|██████████| 1.13G/1.13G [00:06<00:00, 194MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)"
      ],
      "metadata": {
        "id": "xm-d6ERJkBZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', leave=True)\n",
        "\n",
        "    for images, labels in train_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        train_loop.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loop = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]', leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loop.set_postfix({\n",
        "                'loss': f\"{loss.item():.4f}\",\n",
        "                'acc': f\"{correct/total:.4f}\"\n",
        "            })\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = correct / total\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_dinov2_isic2019.pth')\n",
        "        print(f\"\\nNew best model saved with val acc: {val_acc:.4f}\")\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "8efHFigmkCZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2e3ea8-6d71-4ec3-cd4c-07f417bef887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.64s/it, loss=2.6995]\n",
            "Epoch 1/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.4488, acc=0.5905]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.5905\n",
            "\n",
            "Epoch 1 Summary:\n",
            "Train Loss: 1.6238 | Val Loss: 1.3351 | Val Acc: 0.5905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=2.4870]\n",
            "Epoch 2/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.3525, acc=0.5805]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Summary:\n",
            "Train Loss: 1.3157 | Val Loss: 1.1789 | Val Acc: 0.5805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.7003]\n",
            "Epoch 3/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.2686, acc=0.6547]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.6547\n",
            "\n",
            "Epoch 3 Summary:\n",
            "Train Loss: 1.2303 | Val Loss: 1.1177 | Val Acc: 0.6547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.2194]\n",
            "Epoch 4/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1622, acc=0.5976]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 Summary:\n",
            "Train Loss: 1.1632 | Val Loss: 1.1230 | Val Acc: 0.5976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.9578]\n",
            "Epoch 5/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.3333, acc=0.6358]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 Summary:\n",
            "Train Loss: 1.1142 | Val Loss: 1.0707 | Val Acc: 0.6358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.1055]\n",
            "Epoch 6/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.3220, acc=0.6379]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 Summary:\n",
            "Train Loss: 1.0541 | Val Loss: 1.0510 | Val Acc: 0.6379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.1855]\n",
            "Epoch 7/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1329, acc=0.6597]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.6597\n",
            "\n",
            "Epoch 7 Summary:\n",
            "Train Loss: 1.0373 | Val Loss: 1.0411 | Val Acc: 0.6597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=2.2071]\n",
            "Epoch 8/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1675, acc=0.6487]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 Summary:\n",
            "Train Loss: 1.0002 | Val Loss: 1.0175 | Val Acc: 0.6487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=2.4143]\n",
            "Epoch 9/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1474, acc=0.6761]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.6761\n",
            "\n",
            "Epoch 9 Summary:\n",
            "Train Loss: 0.9742 | Val Loss: 0.9802 | Val Acc: 0.6761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.2468]\n",
            "Epoch 10/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.2333, acc=0.6553]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 Summary:\n",
            "Train Loss: 0.9617 | Val Loss: 0.9977 | Val Acc: 0.6553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.5794]\n",
            "Epoch 11/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.2865, acc=0.6634]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 Summary:\n",
            "Train Loss: 0.9482 | Val Loss: 0.9731 | Val Acc: 0.6634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=1.0438]\n",
            "Epoch 12/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1127, acc=0.6955]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.6955\n",
            "\n",
            "Epoch 12 Summary:\n",
            "Train Loss: 0.9150 | Val Loss: 0.9230 | Val Acc: 0.6955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.1247]\n",
            "Epoch 13/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1181, acc=0.6939]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 Summary:\n",
            "Train Loss: 0.9205 | Val Loss: 0.9581 | Val Acc: 0.6939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.3925]\n",
            "Epoch 14/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.2348, acc=0.6668]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 Summary:\n",
            "Train Loss: 0.8868 | Val Loss: 0.9020 | Val Acc: 0.6668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.3738]\n",
            "Epoch 15/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=0.9484, acc=0.7029]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.7029\n",
            "\n",
            "Epoch 15 Summary:\n",
            "Train Loss: 0.8545 | Val Loss: 0.9045 | Val Acc: 0.7029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.5868]\n",
            "Epoch 16/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.0431, acc=0.6918]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16 Summary:\n",
            "Train Loss: 0.8529 | Val Loss: 0.8888 | Val Acc: 0.6918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.3786]\n",
            "Epoch 17/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1030, acc=0.6913]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17 Summary:\n",
            "Train Loss: 0.8372 | Val Loss: 0.8758 | Val Acc: 0.6913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.6210]\n",
            "Epoch 18/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1483, acc=0.7129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.7129\n",
            "\n",
            "Epoch 18 Summary:\n",
            "Train Loss: 0.8202 | Val Loss: 0.8877 | Val Acc: 0.7129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.7107]\n",
            "Epoch 19/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1748, acc=0.6789]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19 Summary:\n",
            "Train Loss: 0.8157 | Val Loss: 0.8617 | Val Acc: 0.6789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.8157]\n",
            "Epoch 20/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.0846, acc=0.7113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20 Summary:\n",
            "Train Loss: 0.7968 | Val Loss: 0.8718 | Val Acc: 0.7113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.3837]\n",
            "Epoch 21/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1754, acc=0.6921]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21 Summary:\n",
            "Train Loss: 0.7927 | Val Loss: 0.8630 | Val Acc: 0.6921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.4400]\n",
            "Epoch 22/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.0526, acc=0.6858]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 22 Summary:\n",
            "Train Loss: 0.7974 | Val Loss: 0.8625 | Val Acc: 0.6858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.8585]\n",
            "Epoch 23/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1203, acc=0.6842]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23 Summary:\n",
            "Train Loss: 0.7576 | Val Loss: 0.8455 | Val Acc: 0.6842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.5481]\n",
            "Epoch 24/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1368, acc=0.7116]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24 Summary:\n",
            "Train Loss: 0.7356 | Val Loss: 0.8351 | Val Acc: 0.7116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.6012]\n",
            "Epoch 25/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=0.9677, acc=0.6984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 25 Summary:\n",
            "Train Loss: 0.7290 | Val Loss: 0.8299 | Val Acc: 0.6984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 9: Final Evaluation ---\n",
        "model.load_state_dict(torch.load('best_dinov2_isic2019.pth'))\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "test_loop = tqdm(test_loader, desc='Testing', leave=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loop.set_postfix({'acc': f\"{test_correct/test_total:.4f}\"})\n",
        "\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OhxD4SykFKT",
        "outputId": "629c14ac-0d57-4563-bf36-cbfbf1f7aa8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-f1790a0a500c>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_dinov2_isic2019.pth'))\n",
            "Testing: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, acc=0.7166]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy: 0.7166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aoQG-f29ZNuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "\n",
        "# Check if ONNX model is valid\n",
        "try:\n",
        "    ort.InferenceSession(\"dinov2_ham10000.onnx\")\n",
        "    print(\"ONNX model is valid.\")\n",
        "except Exception as e:\n",
        "    print(f\"ONNX validation failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtd9W6QFSdtg",
        "outputId": "ed99be4d-2935-4387-eb12-4bae81e8b956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model is valid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)  # Suppress verbose logs\n",
        "builder = trt.Builder(TRT_LOGGER)"
      ],
      "metadata": {
        "id": "nnJ7ybjxSiJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    \"dinov2_ham10000.onnx\",\n",
        "    opset_version=17,\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
        ")"
      ],
      "metadata": {
        "id": "RGBIlXw8-gqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0b43dc-ef09-4815-d393-3b566199144f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/patch_embed.py:72: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/patch_embed.py:73: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert W % patch_W == 0, f\"Input image width {W} is not a multiple of patch width: {patch_W}\"\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py:183: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if npatch == N and w == h:\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py:191: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  M = int(math.sqrt(N))  # Recover the number of patches in each dimension\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py:192: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert N == M * M\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py:197: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  sx = float(w0 + self.interpolate_offset) / M\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py:198: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  sy = float(h0 + self.interpolate_offset) / M\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py:209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert (w0, h0) == patch_pos_embed.shape[-2:]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HAM10000Calibrator(trt.IInt8EntropyCalibrator2):\n",
        "    def __init__(self, data_loader, cache_file=\"ham10000.cache\"):\n",
        "        super().__init__()\n",
        "        self.data_loader = data_loader\n",
        "        self.cache_file = cache_file\n",
        "        self.device_input = cuda.mem_alloc(1 * 3 * 224 * 224 * np.float32().itemsize)\n",
        "        self.current_idx = 0\n",
        "        self.data_iter = iter(data_loader)\n",
        "\n",
        "    def get_batch(self, names):\n",
        "        try:\n",
        "            images, _ = next(self.data_iter)\n",
        "            images = images.numpy().astype(np.float32)\n",
        "            cuda.memcpy_htod(self.device_input, images.ravel())\n",
        "            return [int(self.device_input)]\n",
        "        except StopIteration:\n",
        "            return None\n",
        "\n",
        "    def read_calibration_cache(self):\n",
        "        if os.path.exists(self.cache_file):\n",
        "            with open(self.cache_file, \"rb\") as f:\n",
        "                return f.read()\n",
        "\n",
        "    def write_calibration_cache(self, cache):\n",
        "        with open(self.cache_file, \"wb\") as f:\n",
        "            f.write(cache)"
      ],
      "metadata": {
        "id": "CdcvvE8x_Rb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
        "with trt.Builder(TRT_LOGGER) as builder, \\\n",
        "     builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network:\n",
        "\n",
        "    # Parse ONNX\n",
        "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "    with open(\"dinov2_ham10000.onnx\", \"rb\") as f:\n",
        "        if not parser.parse(f.read()):\n",
        "            for error in range(parser.num_errors):\n",
        "                print(parser.get_error(error))\n",
        "            raise ValueError(\"Failed to parse ONNX\")\n",
        "\n",
        "    # Configure INT8\n",
        "    config = builder.create_builder_config()\n",
        "    config.set_flag(trt.BuilderFlag.INT8)\n",
        "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 20 << 30)\n",
        "\n",
        "\n",
        "    # Set Calibrator\n",
        "    calib_loader = train_loader\n",
        "    calibrator = HAM10000Calibrator(calib_loader)\n",
        "    config.int8_calibrator = calibrator\n",
        "\n",
        "    config.profiling_verbosity = trt.ProfilingVerbosity.DETAILED\n",
        "    config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "    # Build Engine\n",
        "    engine = builder.build_serialized_network(network, config)\n",
        "\n",
        "# Save Engine\n",
        "if engine:\n",
        "    with open(\"dinov2_ham10000_int8.engine\", \"wb\") as f:\n",
        "        f.write(engine)\n",
        "else:\n",
        "    print(\"Engine build failed.\")"
      ],
      "metadata": {
        "id": "QahekcjnDn2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab47f9e-856e-4f3a-8eb4-7c08be1a78cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engine build failed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-9c5fad86d035>:22: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
            "  config.int8_calibrator = calibrator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorRT inference\n",
        "start = cuda.Event()\n",
        "end = cuda.Event()\n",
        "start.record()\n",
        "context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
        "end.record()\n",
        "cuda.synchronize()\n",
        "print(\"Time (ms):\", start.time_till(end))"
      ],
      "metadata": {
        "id": "u0G5dxyADphM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yidYdxSh18Wf",
        "outputId": "29fcc3d8-8815-400f-c363-edb6646ade89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libnvinfer-bin libnvinfer-dev libnvinfer-dispatch-dev libnvinfer-dispatch10\n",
            "  libnvinfer-headers-dev libnvinfer-headers-plugin-dev libnvinfer-lean-dev\n",
            "  libnvinfer-lean10 libnvinfer-plugin-dev libnvinfer-plugin10\n",
            "  libnvinfer-samples libnvinfer-vc-plugin-dev libnvinfer-vc-plugin10\n",
            "  libnvinfer10 libnvonnxparsers-dev libnvonnxparsers10 python3-libnvinfer\n",
            "  python3-libnvinfer-dev python3-libnvinfer-dispatch python3-libnvinfer-lean\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-bin libnvinfer-dev libnvinfer-dispatch-dev libnvinfer-dispatch10\n",
            "  libnvinfer-headers-dev libnvinfer-headers-plugin-dev libnvinfer-lean-dev\n",
            "  libnvinfer-lean10 libnvinfer-plugin-dev libnvinfer-plugin10\n",
            "  libnvinfer-samples libnvinfer-vc-plugin-dev libnvinfer-vc-plugin10\n",
            "  libnvinfer10 libnvonnxparsers-dev libnvonnxparsers10 python3-libnvinfer\n",
            "  python3-libnvinfer-dev python3-libnvinfer-dispatch python3-libnvinfer-lean\n",
            "  tensorrt\n",
            "0 upgraded, 21 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 2,730 MB of archives.\n",
            "After this operation, 7,045 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer10 10.7.0.23-1+cuda12.6 [1,240 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-lean10 10.7.0.23-1+cuda12.6 [8,232 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin10 10.7.0.23-1+cuda12.6 [9,874 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-vc-plugin10 10.7.0.23-1+cuda12.6 [223 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dispatch10 10.7.0.23-1+cuda12.6 [213 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvonnxparsers10 10.7.0.23-1+cuda12.6 [1,324 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-bin 10.7.0.23-1+cuda12.6 [461 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-dev 10.7.0.23-1+cuda12.6 [106 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dev 10.7.0.23-1+cuda12.6 [1,246 MB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-dispatch-dev 10.7.0.23-1+cuda12.6 [124 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-headers-plugin-dev 10.7.0.23-1+cuda12.6 [6,060 B]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-lean-dev 10.7.0.23-1+cuda12.6 [21.6 MB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-plugin-dev 10.7.0.23-1+cuda12.6 [11.3 MB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-vc-plugin-dev 10.7.0.23-1+cuda12.6 [80.4 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvonnxparsers-dev 10.7.0.23-1+cuda12.6 [2,147 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvinfer-samples 10.7.0.23-1+cuda12.6 [187 MB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer 10.7.0.23-1+cuda12.6 [810 kB]\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer-lean 10.7.0.23-1+cuda12.6 [504 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer-dispatch 10.7.0.23-1+cuda12.6 [504 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  python3-libnvinfer-dev 10.7.0.23-1+cuda12.6 [2,962 B]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  tensorrt 10.7.0.23-1+cuda12.6 [2,946 B]\n",
            "Fetched 2,730 MB in 38s (71.3 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 21.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libnvinfer10.\n",
            "(Reading database ... 123635 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libnvinfer10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-lean10.\n",
            "Preparing to unpack .../01-libnvinfer-lean10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-lean10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-plugin10.\n",
            "Preparing to unpack .../02-libnvinfer-plugin10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-vc-plugin10.\n",
            "Preparing to unpack .../03-libnvinfer-vc-plugin10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-vc-plugin10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-dispatch10.\n",
            "Preparing to unpack .../04-libnvinfer-dispatch10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-dispatch10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvonnxparsers10.\n",
            "Preparing to unpack .../05-libnvonnxparsers10_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvonnxparsers10 (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-bin.\n",
            "Preparing to unpack .../06-libnvinfer-bin_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-bin (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-headers-dev.\n",
            "Preparing to unpack .../07-libnvinfer-headers-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-headers-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-dev.\n",
            "Preparing to unpack .../08-libnvinfer-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-dispatch-dev.\n",
            "Preparing to unpack .../09-libnvinfer-dispatch-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-dispatch-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-headers-plugin-dev.\n",
            "Preparing to unpack .../10-libnvinfer-headers-plugin-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-headers-plugin-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-lean-dev.\n",
            "Preparing to unpack .../11-libnvinfer-lean-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-lean-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-plugin-dev.\n",
            "Preparing to unpack .../12-libnvinfer-plugin-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-vc-plugin-dev.\n",
            "Preparing to unpack .../13-libnvinfer-vc-plugin-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvinfer-vc-plugin-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvonnxparsers-dev.\n",
            "Preparing to unpack .../14-libnvonnxparsers-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking libnvonnxparsers-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package libnvinfer-samples.\n",
            "Preparing to unpack .../15-libnvinfer-samples_10.7.0.23-1+cuda12.6_all.deb ...\n",
            "Unpacking libnvinfer-samples (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package python3-libnvinfer.\n",
            "Preparing to unpack .../16-python3-libnvinfer_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking python3-libnvinfer (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package python3-libnvinfer-lean.\n",
            "Preparing to unpack .../17-python3-libnvinfer-lean_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking python3-libnvinfer-lean (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package python3-libnvinfer-dispatch.\n",
            "Preparing to unpack .../18-python3-libnvinfer-dispatch_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking python3-libnvinfer-dispatch (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package python3-libnvinfer-dev.\n",
            "Preparing to unpack .../19-python3-libnvinfer-dev_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking python3-libnvinfer-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Selecting previously unselected package tensorrt.\n",
            "Preparing to unpack .../20-tensorrt_10.7.0.23-1+cuda12.6_amd64.deb ...\n",
            "Unpacking tensorrt (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-headers-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-plugin10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-vc-plugin10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvonnxparsers10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-dispatch10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-dispatch-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-lean10 (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvonnxparsers-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up python3-libnvinfer-dispatch (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-headers-plugin-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-lean-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up python3-libnvinfer (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up python3-libnvinfer-lean (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-plugin-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-vc-plugin-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-bin (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up libnvinfer-samples (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up python3-libnvinfer-dev (10.7.0.23-1+cuda12.6) ...\n",
            "Setting up tensorrt (10.7.0.23-1+cuda12.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/src/tensorrt/samples/trtexec/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeG1IejgY0pU",
        "outputId": "ad60e382-acb0-4d46-bd6d-4dc8ea27c893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /usr/src/tensorrt/samples/trtexec/trtexec: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!trtexec --onnx=dinov2_ham10000.onnx --int8 --saveEngine=model.engine --verbose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPDrJ6Ntu686",
        "outputId": "5ce7ea20-1cef-41f1-b6c0-667f97143e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: trtexec: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo --quiet"
      ],
      "metadata": {
        "id": "q-EoG1mrge-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2hi0H_-iLpQ",
        "outputId": "4704503c-7365-4935-b147-b42425949983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "DINOv2Classifier                              [1, 8]                    --\n",
              "├─DinoVisionTransformer: 1-1                  [1, 1024]                 1,404,928\n",
              "│    └─PatchEmbed: 2-1                        [1, 256, 1024]            --\n",
              "│    │    └─Conv2d: 3-1                       [1, 1024, 16, 16]         (603,136)\n",
              "│    │    └─Identity: 3-2                     [1, 256, 1024]            --\n",
              "│    └─ModuleList: 2-2                        --                        --\n",
              "│    │    └─NestedTensorBlock: 3-3            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-4            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-5            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-6            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-7            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-8            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-9            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-10           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-11           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-12           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-13           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-14           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-15           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-16           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-17           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-18           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-19           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-20           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-21           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-22           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-23           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-24           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-25           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-26           [1, 257, 1024]            (12,598,272)\n",
              "│    └─LayerNorm: 2-3                         [1, 257, 1024]            (2,048)\n",
              "│    └─Identity: 2-4                          [1, 1024]                 --\n",
              "├─Sequential: 1-2                             [1, 8]                    --\n",
              "│    └─Linear: 2-5                            [1, 512]                  524,800\n",
              "│    └─ReLU: 2-6                              [1, 512]                  --\n",
              "│    └─Dropout: 2-7                           [1, 512]                  --\n",
              "│    └─Linear: 2-8                            [1, 8]                    4,104\n",
              "===============================================================================================\n",
              "Total params: 304,897,544\n",
              "Trainable params: 528,904\n",
              "Non-trainable params: 304,368,640\n",
              "Total mult-adds (M): 457.24\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 661.07\n",
              "Params size (MB): 1213.97\n",
              "Estimated Total Size (MB): 1875.65\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DINOv2Full(nn.Module):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super().__init__()\n",
        "        self.dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.dinov2.embed_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "        # for param in self.dinov2.parameters():\n",
        "        #     param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get all image features (batch_size, num_patches, embed_dim)\n",
        "        features = self.dinov2(x)\n",
        "\n",
        "        # Handle different output formats:\n",
        "        if features.dim() == 3:  # Standard case with spatial dimensions\n",
        "            cls_token = features[:, 0, :]  # Extract [CLS] token\n",
        "        else:  # Fallback for 2D output\n",
        "            cls_token = features\n",
        "\n",
        "        return self.classifier(cls_token)\n",
        "\n",
        "model2 = DINOv2Full().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubVFtkRgidk5",
        "outputId": "c5ad29bc-8896-4051-f6fe-fcd73de55591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model2, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1c2LzoNip2B",
        "outputId": "93bf01a3-2397-4d1f-e900-b9d81b2a8b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "DINOv2Full                                    [1, 8]                    --\n",
              "├─DinoVisionTransformer: 1-1                  [1, 1024]                 1,404,928\n",
              "│    └─PatchEmbed: 2-1                        [1, 256, 1024]            --\n",
              "│    │    └─Conv2d: 3-1                       [1, 1024, 16, 16]         603,136\n",
              "│    │    └─Identity: 3-2                     [1, 256, 1024]            --\n",
              "│    └─ModuleList: 2-2                        --                        --\n",
              "│    │    └─NestedTensorBlock: 3-3            [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-4            [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-5            [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-6            [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-7            [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-8            [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-9            [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-10           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-11           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-12           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-13           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-14           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-15           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-16           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-17           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-18           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-19           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-20           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-21           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-22           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-23           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-24           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-25           [1, 257, 1024]            12,598,272\n",
              "│    │    └─NestedTensorBlock: 3-26           [1, 257, 1024]            12,598,272\n",
              "│    └─LayerNorm: 2-3                         [1, 257, 1024]            2,048\n",
              "│    └─Identity: 2-4                          [1, 1024]                 --\n",
              "├─Sequential: 1-2                             [1, 8]                    --\n",
              "│    └─Linear: 2-5                            [1, 512]                  524,800\n",
              "│    └─ReLU: 2-6                              [1, 512]                  --\n",
              "│    └─Dropout: 2-7                           [1, 512]                  --\n",
              "│    └─Linear: 2-8                            [1, 8]                    4,104\n",
              "===============================================================================================\n",
              "Total params: 304,897,544\n",
              "Trainable params: 304,897,544\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 457.24\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 661.07\n",
              "Params size (MB): 1213.97\n",
              "Estimated Total Size (MB): 1875.65\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.ao.quantization import get_default_qconfig\n",
        "from torch.ao.quantization.quantize_fx import convert_fx, prepare_fx"
      ],
      "metadata": {
        "id": "ZAH3haM_qaeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNp9Tyd0qbdI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}