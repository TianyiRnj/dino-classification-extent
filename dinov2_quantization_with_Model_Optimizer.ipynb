{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l1SzyWjzjhqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fcb015-4f8d-4f18-8050-b9653b821805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pandas numpy matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo --quiet"
      ],
      "metadata": {
        "id": "5yHq_0kUnEkA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zruaxu6jlhUQ",
        "outputId": "b487b01d-1bb1-432c-df9e-31f5d2a3623e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.4.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --upgrade tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35Kcl-Jj_x1m",
        "outputId": "6518c1e3-8d9a-4281-d156-fe1eaff9fabd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-10.9.0.34.tar.gz (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12==10.9.0.34 (from tensorrt)\n",
            "  Downloading tensorrt_cu12-10.9.0.34.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_libs==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
            "  Downloading tensorrt_cu12_libs-10.9.0.34.tar.gz (704 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_bindings==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
            "  Downloading tensorrt_cu12_bindings-10.9.0.34-cp311-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt_cu12_libs==10.9.0.34->tensorrt_cu12==10.9.0.34->tensorrt) (12.4.127)\n",
            "Downloading tensorrt_cu12_bindings-10.9.0.34-cp311-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.9.0.34-py2.py3-none-any.whl size=46629 sha256=457c171dc70a9bcda1c58ac5f6157fd898fd7b7cfee6fa31d1f21c468d206b75\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/4d/72/f28cb367f1435d026243047d4f60fde8f1c9cbb06a204f842f\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.9.0.34-py2.py3-none-any.whl size=17465 sha256=d19175e2dcf4d3d4dea0b002ef04dc0a4d2afe012411bf07bb5d537e48be3e1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/09/76/6b405075fe4c04097f5713ec0a688df7892aaee823bc141952\n",
            "  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.9.0.34-py2.py3-none-manylinux_2_28_x86_64.whl size=3103291777 sha256=4a82f0bda2874596f202f6edc8dae99b86a3c4ec2fa142a9c847c4d3a57864a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/d0/06/35d7b3006eead25828debb658da848328ebfd38962a2bcd096\n",
            "Successfully built tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
            "Installing collected packages: tensorrt_cu12_bindings, tensorrt_cu12_libs, tensorrt_cu12, tensorrt\n",
            "Successfully installed tensorrt-10.9.0.34 tensorrt_cu12-10.9.0.34 tensorrt_cu12_bindings-10.9.0.34 tensorrt_cu12_libs-10.9.0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "!kaggle datasets download andrewmvd/isic-2019\n",
        "!unzip -q isic-2019.zip"
      ],
      "metadata": {
        "id": "7z6HP5mVj6Kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dfffdea-1a15-42a2-85d4-00b780977dee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/isic-2019\n",
            "License(s): Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
            "Downloading isic-2019.zip to /content\n",
            "100% 9.09G/9.10G [07:31<00:00, 22.4MB/s]\n",
            "100% 9.10G/9.10G [07:31<00:00, 21.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda onnx onnxsim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfBncMXtiC75",
        "outputId": "f944e445-5eab-46d2-c1b6-e93252baf6ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.25.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from onnxsim) (13.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytools-2025.1.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660393 sha256=b4da248574d098676932bdd9513ee92a3344e937601d3a7863e5846c5e3e5e1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, onnx, mako, pycuda, onnxsim\n",
            "Successfully installed mako-1.3.9 onnx-1.17.0 onnxsim-0.4.36 pycuda-2025.1 pytools-2025.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "uvIBd2bsegY4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorRT and CUDA\n",
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit  # Initializes CUDA context\n",
        "\n",
        "import onnx\n",
        "from onnxsim import simplify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "vcgQRMYhiHPn",
        "outputId": "618057be-b7fc-4b66-c296-b6f293468008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mInstalling onnxruntime by `/usr/bin/python3 -m pip install onnxruntime`, please wait for a moment..\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Installing onnxruntime by `/usr/bin/python3 -m pip install onnxruntime`, please wait for a moment..</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Organize Data ---\n",
        "# Load metadata\n",
        "train_meta = pd.read_csv('ISIC_2019_Training_GroundTruth.csv')\n",
        "train_meta['image'] = train_meta['image'] + '.jpg'\n",
        "\n",
        "# Convert one-hot encoding to class labels\n",
        "classes = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n",
        "train_meta['label'] = train_meta[classes].idxmax(axis=1)\n",
        "label_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n"
      ],
      "metadata": {
        "id": "OfIr73lyeh3A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(train_meta, test_size=0.3,\n",
        "                                    stratify=train_meta['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5,\n",
        "                                  stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "# --- Step 3: Define Dataset Class ---\n",
        "class ISIC2019Dataset(Dataset):\n",
        "    def __init__(self, df, img_dir='ISIC_2019_Training_Input/ISIC_2019_Training_Input', transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.label_to_idx = label_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.df.iloc[idx]['image'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.label_to_idx[self.df.iloc[idx]['label']]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "4oYEH2aBj7xD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Data Transforms and Loaders ---\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create datasets and loaders\n",
        "batch_size = 64\n",
        "train_dataset = ISIC2019Dataset(train_df, transform=train_transform)\n",
        "val_dataset = ISIC2019Dataset(val_df, transform=val_transform)\n",
        "test_dataset = ISIC2019Dataset(test_df, transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "Fshz4BxQj95f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaedbacb-3906-4c13-9900-a1bfe62a6e6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Model Setup ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- Step 5: Handle Class Imbalance ---\n",
        "train_labels = [label for _, label in train_dataset]\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
      ],
      "metadata": {
        "id": "zIG4o9GAfVYF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DINOv2Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super().__init__()\n",
        "        self.dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.dinov2.embed_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "        for param in self.dinov2.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get all image features (batch_size, num_patches, embed_dim)\n",
        "        features = self.dinov2(x)\n",
        "\n",
        "        # Handle different output formats:\n",
        "        if features.dim() == 3:  # Standard case with spatial dimensions\n",
        "            cls_token = features[:, 0, :]  # Extract [CLS] token\n",
        "        else:  # Fallback for 2D output\n",
        "            cls_token = features\n",
        "\n",
        "        return self.classifier(cls_token)\n",
        "\n",
        "model = DINOv2Classifier().to(device)"
      ],
      "metadata": {
        "id": "RYjSSyvtj_G6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d037416-477c-4398-feae-883351f863a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)"
      ],
      "metadata": {
        "id": "xm-d6ERJkBZx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', leave=True)\n",
        "\n",
        "    for images, labels in train_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        train_loop.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loop = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]', leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loop.set_postfix({\n",
        "                'loss': f\"{loss.item():.4f}\",\n",
        "                'acc': f\"{correct/total:.4f}\"\n",
        "            })\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = correct / total\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_dinov2_isic2019.pth')\n",
        "        print(f\"\\nNew best model saved with val acc: {val_acc:.4f}\")\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "8efHFigmkCZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2e3ea8-6d71-4ec3-cd4c-07f417bef887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.64s/it, loss=2.6995]\n",
            "Epoch 1/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.4488, acc=0.5905]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.5905\n",
            "\n",
            "Epoch 1 Summary:\n",
            "Train Loss: 1.6238 | Val Loss: 1.3351 | Val Acc: 0.5905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=2.4870]\n",
            "Epoch 2/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.3525, acc=0.5805]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Summary:\n",
            "Train Loss: 1.3157 | Val Loss: 1.1789 | Val Acc: 0.5805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.7003]\n",
            "Epoch 3/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.2686, acc=0.6547]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.6547\n",
            "\n",
            "Epoch 3 Summary:\n",
            "Train Loss: 1.2303 | Val Loss: 1.1177 | Val Acc: 0.6547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.2194]\n",
            "Epoch 4/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1622, acc=0.5976]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 Summary:\n",
            "Train Loss: 1.1632 | Val Loss: 1.1230 | Val Acc: 0.5976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.9578]\n",
            "Epoch 5/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.3333, acc=0.6358]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 Summary:\n",
            "Train Loss: 1.1142 | Val Loss: 1.0707 | Val Acc: 0.6358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.1055]\n",
            "Epoch 6/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.3220, acc=0.6379]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 Summary:\n",
            "Train Loss: 1.0541 | Val Loss: 1.0510 | Val Acc: 0.6379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.1855]\n",
            "Epoch 7/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1329, acc=0.6597]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.6597\n",
            "\n",
            "Epoch 7 Summary:\n",
            "Train Loss: 1.0373 | Val Loss: 1.0411 | Val Acc: 0.6597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=2.2071]\n",
            "Epoch 8/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1675, acc=0.6487]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 Summary:\n",
            "Train Loss: 1.0002 | Val Loss: 1.0175 | Val Acc: 0.6487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=2.4143]\n",
            "Epoch 9/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1474, acc=0.6761]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.6761\n",
            "\n",
            "Epoch 9 Summary:\n",
            "Train Loss: 0.9742 | Val Loss: 0.9802 | Val Acc: 0.6761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.2468]\n",
            "Epoch 10/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.2333, acc=0.6553]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 Summary:\n",
            "Train Loss: 0.9617 | Val Loss: 0.9977 | Val Acc: 0.6553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.5794]\n",
            "Epoch 11/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.65s/it, loss=1.2865, acc=0.6634]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 Summary:\n",
            "Train Loss: 0.9482 | Val Loss: 0.9731 | Val Acc: 0.6634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=1.0438]\n",
            "Epoch 12/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1127, acc=0.6955]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.6955\n",
            "\n",
            "Epoch 12 Summary:\n",
            "Train Loss: 0.9150 | Val Loss: 0.9230 | Val Acc: 0.6955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.1247]\n",
            "Epoch 13/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1181, acc=0.6939]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 Summary:\n",
            "Train Loss: 0.9205 | Val Loss: 0.9581 | Val Acc: 0.6939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.3925]\n",
            "Epoch 14/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.2348, acc=0.6668]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 Summary:\n",
            "Train Loss: 0.8868 | Val Loss: 0.9020 | Val Acc: 0.6668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.3738]\n",
            "Epoch 15/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=0.9484, acc=0.7029]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.7029\n",
            "\n",
            "Epoch 15 Summary:\n",
            "Train Loss: 0.8545 | Val Loss: 0.9045 | Val Acc: 0.7029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/25 [Train]: 100%|██████████| 278/278 [07:34<00:00,  1.63s/it, loss=0.5868]\n",
            "Epoch 16/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.0431, acc=0.6918]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16 Summary:\n",
            "Train Loss: 0.8529 | Val Loss: 0.8888 | Val Acc: 0.6918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.3786]\n",
            "Epoch 17/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1030, acc=0.6913]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17 Summary:\n",
            "Train Loss: 0.8372 | Val Loss: 0.8758 | Val Acc: 0.6913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.6210]\n",
            "Epoch 18/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1483, acc=0.7129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New best model saved with val acc: 0.7129\n",
            "\n",
            "Epoch 18 Summary:\n",
            "Train Loss: 0.8202 | Val Loss: 0.8877 | Val Acc: 0.7129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.7107]\n",
            "Epoch 19/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1748, acc=0.6789]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19 Summary:\n",
            "Train Loss: 0.8157 | Val Loss: 0.8617 | Val Acc: 0.6789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.8157]\n",
            "Epoch 20/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.0846, acc=0.7113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20 Summary:\n",
            "Train Loss: 0.7968 | Val Loss: 0.8718 | Val Acc: 0.7113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.3837]\n",
            "Epoch 21/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1754, acc=0.6921]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21 Summary:\n",
            "Train Loss: 0.7927 | Val Loss: 0.8630 | Val Acc: 0.6921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=0.4400]\n",
            "Epoch 22/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.0526, acc=0.6858]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 22 Summary:\n",
            "Train Loss: 0.7974 | Val Loss: 0.8625 | Val Acc: 0.6858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.8585]\n",
            "Epoch 23/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1203, acc=0.6842]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23 Summary:\n",
            "Train Loss: 0.7576 | Val Loss: 0.8455 | Val Acc: 0.6842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.5481]\n",
            "Epoch 24/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=1.1368, acc=0.7116]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24 Summary:\n",
            "Train Loss: 0.7356 | Val Loss: 0.8351 | Val Acc: 0.7116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/25 [Train]: 100%|██████████| 278/278 [07:33<00:00,  1.63s/it, loss=1.6012]\n",
            "Epoch 25/25 [Val]: 100%|██████████| 60/60 [01:38<00:00,  1.64s/it, loss=0.9677, acc=0.6984]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 25 Summary:\n",
            "Train Loss: 0.7290 | Val Loss: 0.8299 | Val Acc: 0.6984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_dinov2_large.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a0i-1GuoD_D",
        "outputId": "fe9dd3ab-c59b-487a-e5ff-e8de71108a63"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 9: Final Evaluation ---\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "test_loop = tqdm(test_loader, desc='Testing', leave=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loop.set_postfix({'acc': f\"{test_correct/test_total:.4f}\"})\n",
        "\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OhxD4SykFKT",
        "outputId": "fefa0844-5983-4454-a61a-410385334996"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTesting:   0%|          | 0/60 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Testing: 100%|██████████| 60/60 [03:14<00:00,  3.24s/it, acc=0.7158]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy: 0.7158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"nvidia-modelopt[all]\" -U --extra-index-url https://pypi.nvidia.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MDMgqkH_lhsz",
        "outputId": "ead4bb1e-afc9-433e-c965-402fcdecc87a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting nvidia-modelopt[all]\n",
            "  Downloading https://pypi.nvidia.com/nvidia-modelopt/nvidia_modelopt-0.25.0-py3-none-manylinux2014_x86_64.whl (616 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.5/616.5 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-modelopt-core==0.25.0 (from nvidia-modelopt[all])\n",
            "  Downloading https://pypi.nvidia.com/nvidia-modelopt-core/nvidia_modelopt_core-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (3.1.1)\n",
            "Collecting ninja (from nvidia-modelopt[all])\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting numpy<2 (from nvidia-modelopt[all])\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (2.10.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (13.9.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (4.67.1)\n",
            "Collecting cppimport (from nvidia-modelopt[all])\n",
            "  Downloading cppimport-22.8.2.tar.gz (26 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (13.3.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (1.17.0)\n",
            "Collecting onnxconverter-common (from nvidia-modelopt[all])\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting onnxmltools (from nvidia-modelopt[all])\n",
            "  Downloading onnxmltools-1.13.0-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting onnx-graphsurgeon (from nvidia-modelopt[all])\n",
            "  Downloading https://pypi.nvidia.com/onnx-graphsurgeon/onnx_graphsurgeon-0.5.6-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime-gpu~=1.20.1 (from nvidia-modelopt[all])\n",
            "  Downloading onnxruntime_gpu-1.20.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting pulp (from nvidia-modelopt[all])\n",
            "  Downloading PuLP-3.0.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (2024.11.6)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (0.5.3)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (2.6.0+cu124)\n",
            "Collecting torchprofile>=0.0.4 (from nvidia-modelopt[all])\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (0.21.0+cu124)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (12.0.0)\n",
            "Requirement already satisfied: accelerate>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (1.3.0)\n",
            "Requirement already satisfied: datasets>=2.16.1 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (3.4.1)\n",
            "Requirement already satisfied: diffusers>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (0.32.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (0.28.1)\n",
            "Requirement already satisfied: transformers>=4.40.2 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (4.48.3)\n",
            "Requirement already satisfied: peft>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from nvidia-modelopt[all]) (0.14.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.27.2->nvidia-modelopt[all]) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.27.2->nvidia-modelopt[all]) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.1->nvidia-modelopt[all]) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.1->nvidia-modelopt[all]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.1->nvidia-modelopt[all]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.1->nvidia-modelopt[all]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.1->nvidia-modelopt[all]) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.1->nvidia-modelopt[all]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.1->nvidia-modelopt[all]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.1->nvidia-modelopt[all]) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.1->nvidia-modelopt[all]) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.27.2->nvidia-modelopt[all]) (8.6.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.27.2->nvidia-modelopt[all]) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24.0->nvidia-modelopt[all]) (4.12.2)\n",
            "Collecting coloredlogs (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->nvidia-modelopt[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->nvidia-modelopt[all]) (2.27.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->nvidia-modelopt[all]) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu~=1.20.1->nvidia-modelopt[all]) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.2->nvidia-modelopt[all]) (0.21.1)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.11/dist-packages (from cppimport->nvidia-modelopt[all]) (1.3.9)\n",
            "Collecting pybind11 (from cppimport->nvidia-modelopt[all])\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->nvidia-modelopt[all]) (0.8.3)\n",
            "Collecting protobuf (from onnxruntime-gpu~=1.20.1->nvidia-modelopt[all])\n",
            "  Downloading protobuf-3.20.2-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->nvidia-modelopt[all]) (12.570.86)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->nvidia-modelopt[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->nvidia-modelopt[all]) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.1->nvidia-modelopt[all]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.1->nvidia-modelopt[all]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.1->nvidia-modelopt[all]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.1->nvidia-modelopt[all]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.1->nvidia-modelopt[all]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.1->nvidia-modelopt[all]) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.1->nvidia-modelopt[all]) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->nvidia-modelopt[all]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.1->nvidia-modelopt[all]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.1->nvidia-modelopt[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.1->nvidia-modelopt[all]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.1->nvidia-modelopt[all]) (2025.1.31)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu~=1.20.1->nvidia-modelopt[all])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers>=0.27.2->nvidia-modelopt[all]) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2->nvidia-modelopt[all]) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.1->nvidia-modelopt[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.1->nvidia-modelopt[all]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.1->nvidia-modelopt[all]) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.1->nvidia-modelopt[all]) (1.17.0)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.20.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxmltools-1.13.0-py2.py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PuLP-3.0.2-py3-none-any.whl (17.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: cppimport\n",
            "  Building wheel for cppimport (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cppimport: filename=cppimport-22.8.2-py3-none-any.whl size=17699 sha256=f7a6fc12cab46fc31a247ed0734c3c507e13aab40e953d01a049ec206ba4bd6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/74/c3/da98286e4d715a502b9ecbc9d439406597959debe0a0d0a079\n",
            "Successfully built cppimport\n",
            "Installing collected packages: pybind11, pulp, protobuf, nvidia-modelopt-core, numpy, ninja, humanfriendly, cppimport, coloredlogs, onnxruntime-gpu, onnxconverter-common, onnx-graphsurgeon, nvidia-modelopt, onnxmltools, torchprofile\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.2 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-15.0.1 cppimport-22.8.2 humanfriendly-10.0 ninja-1.11.1.3 numpy-1.26.4 nvidia-modelopt-0.25.0 nvidia-modelopt-core-0.25.0 onnx-graphsurgeon-0.5.6 onnxconverter-common-1.14.0 onnxmltools-1.13.0 onnxruntime-gpu-1.20.2 protobuf-3.20.2 pulp-3.0.2 pybind11-2.13.6 torchprofile-0.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "cc34ea094c52431da3e03ff42bed3be4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import modelopt.torch.quantization as mtq\n",
        "import copy\n",
        "\n",
        "# Setup the model\n",
        "model_pre_q = copy.deepcopy(model).to(device)\n",
        "\n",
        "# Select quantization config\n",
        "config = mtq.INT8_SMOOTHQUANT_CFG\n",
        "\n",
        "# Quantization need calibration data. Setup calibration data loader\n",
        "# An example of creating a calibration data loader looks like the following:\n",
        "data_loader = val_loader\n",
        "\n",
        "\n",
        "# Define forward_loop. Please wrap the data loader in the forward_loop\n",
        "def forward_loop(model):\n",
        "    for images, labels in data_loader:\n",
        "        images = images.to(device)\n",
        "        model(images)\n",
        "\n",
        "\n",
        "# Quantize the model and perform calibration (PTQ)\n",
        "model_q = mtq.quantize(model_pre_q, config, forward_loop)"
      ],
      "metadata": {
        "id": "aoQG-f29ZNuq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbbce35-62c4-401f-a6c2-adba7ba52364"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 297 quantizers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoothed 98 modules\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mtq.print_quant_summary(model_q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XzOSSO5pwUB",
        "outputId": "8b446bf9-ccf2-4231-ea41-79a07a51063a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dinov2.patch_embed.proj.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=2.6400 calibrator=MaxCalibrator quant)\n",
            "dinov2.patch_embed.proj.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.patch_embed.proj.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0009, 0.0533](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.0.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0265, 4.8921](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.0.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0056, 0.3294](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.0.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.3914, 4.7904](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.0.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.0.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1056, 0.9492](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.1.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0252, 5.3203](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.1.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0079, 0.2145](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.1.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.2909, 5.2399](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.1.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.1.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0954, 0.7323](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.2.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0900, 3.1656](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.2.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0250, 0.2615](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.2.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1971, 3.2735](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.2.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.2.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1119, 0.7713](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.3.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0925, 2.0630](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.3.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0222, 0.2263](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.3.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.2195, 3.0800](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.3.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.3.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0926, 0.6086](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.4.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0946, 4.1730](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.4.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0173, 0.2961](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.4.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1580, 2.9996](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.4.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.4.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0646, 0.9352](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.5.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1099, 2.9456](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.5.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0151, 0.2812](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.5.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.2183, 2.5138](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.5.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.5.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0808, 0.7622](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.6.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1133, 3.2478](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.6.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0344, 0.5652](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.6.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1764, 1.8543](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.6.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.6.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0595, 0.6995](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.7.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1234, 3.3640](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.7.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0121, 0.2502](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.7.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1822, 1.6025](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.7.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.7.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0932, 0.5152](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.8.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1375, 4.4046](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.8.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0588, 0.5255](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.8.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1900, 1.2645](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.8.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.8.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.0844, 0.4658](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.attn.qkv.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.attn.qkv.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.9.attn.qkv.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1233, 4.4373](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.attn.proj.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.attn.proj.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.9.attn.proj.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.0269, 0.2712](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.mlp.fc1.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.mlp.fc1.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.9.mlp.fc1.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1813, 1.6362](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.mlp.fc2.input_quantizer                                          TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.9.mlp.fc2.output_quantizer                                         TensorQuantizer(disabled)\n",
            "dinov2.blocks.9.mlp.fc2.weight_quantizer                                         TensorQuantizer(8 bit fake axis=0 amax=[0.1010, 1.3708](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.10.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1531, 3.5117](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.10.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0789, 0.2774](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.10.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1908, 6.6519](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.10.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.10.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1114, 0.7457](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.11.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1692, 2.8061](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.11.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0301, 0.2772](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.11.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1978, 2.2874](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.11.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.11.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1079, 0.7879](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.12.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1752, 2.7308](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.12.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0680, 0.3413](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.12.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2049, 3.9651](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.12.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.12.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1173, 1.4021](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.13.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1775, 4.3949](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.13.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0646, 0.3262](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.13.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1822, 14.0361](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.13.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.13.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1157, 0.5770](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.14.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1846, 3.2756](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.14.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0671, 0.2912](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.14.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1954, 3.2231](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.14.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.14.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1142, 0.5524](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.15.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1668, 4.1785](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.15.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0572, 0.4331](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.15.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1977, 2.5038](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.15.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.15.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1130, 0.4506](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.16.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1799, 4.0977](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.16.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0752, 1.0027](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.16.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1987, 3.6106](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.16.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.16.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1186, 0.5038](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.17.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1868, 3.7394](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.17.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0650, 0.8045](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.17.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2018, 4.6631](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.17.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.17.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1387, 10.4285](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.18.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1755, 4.2419](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.18.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0609, 0.6017](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.18.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2024, 8.9207](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.18.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.18.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1271, 14.7380](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.19.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.1960, 4.4417](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.19.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0615, 0.4219](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.19.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2459, 8.5032](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.19.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.19.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1279, 6.3941](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.20.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.2189, 4.9504](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.20.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0640, 0.3872](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.20.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2535, 2.1648](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.20.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.20.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1259, 0.8512](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.21.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.2357, 4.0221](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.21.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0621, 1.1703](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.21.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2738, 3.0892](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.21.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.21.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.1765, 1.0567](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.22.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.2436, 4.0446](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.22.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0596, 0.9389](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.22.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2909, 3.2084](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.22.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.22.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2100, 3.3324](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.attn.qkv.input_quantizer                                        TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.attn.qkv.output_quantizer                                       TensorQuantizer(disabled)\n",
            "dinov2.blocks.23.attn.qkv.weight_quantizer                                       TensorQuantizer(8 bit fake axis=0 amax=[0.2111, 4.1870](3072) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.attn.proj.input_quantizer                                       TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.attn.proj.output_quantizer                                      TensorQuantizer(disabled)\n",
            "dinov2.blocks.23.attn.proj.weight_quantizer                                      TensorQuantizer(8 bit fake axis=0 amax=[0.0264, 1.5511](1024) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.mlp.fc1.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.mlp.fc1.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.23.mlp.fc1.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.2602, 6.9990](4096) calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.mlp.fc2.input_quantizer                                         TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "dinov2.blocks.23.mlp.fc2.output_quantizer                                        TensorQuantizer(disabled)\n",
            "dinov2.blocks.23.mlp.fc2.weight_quantizer                                        TensorQuantizer(8 bit fake axis=0 amax=[0.0363, 19.1528](1024) calibrator=MaxCalibrator quant)\n",
            "classifier.0.input_quantizer                                                     TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "classifier.0.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "classifier.0.weight_quantizer                                                    TensorQuantizer(8 bit fake axis=0 amax=[0.1939, 0.4108](512) calibrator=MaxCalibrator quant)\n",
            "classifier.3.input_quantizer                                                     TensorQuantizer(8 bit fake per-tensor amax=1.0000 pre_quant_scale calibrator=MaxCalibrator quant)\n",
            "classifier.3.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "classifier.3.weight_quantizer                                                    TensorQuantizer(8 bit fake axis=0 amax=[0.3838, 0.6763](8) calibrator=MaxCalibrator quant)\n",
            "297 TensorQuantizers found in model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluated quantized model\n",
        "model_q = model_q.to(device)\n",
        "model_q.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "test_loop = tqdm(test_loader, desc='Testing', leave=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_q(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loop.set_postfix({'acc': f\"{test_correct/test_total:.4f}\"})\n",
        "\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZso4le5p-dE",
        "outputId": "8432fca1-6331-4b4e-f74c-f9946b674cbc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTesting:   0%|          | 0/60 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Testing: 100%|██████████| 60/60 [03:13<00:00,  3.23s/it, acc=0.6721]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy: 0.6721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_q.state_dict(), 'quantized_dinov2.pth')"
      ],
      "metadata": {
        "id": "UPJkCwaTveqJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo --quiet"
      ],
      "metadata": {
        "id": "q-EoG1mrge-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2hi0H_-iLpQ",
        "outputId": "9357fe22-0c66-4737-b528-65b8628963a6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "DINOv2Classifier                              [1, 8]                    --\n",
              "├─DinoVisionTransformer: 1-1                  [1, 1024]                 1,404,928\n",
              "│    └─PatchEmbed: 2-1                        [1, 256, 1024]            --\n",
              "│    │    └─Conv2d: 3-1                       [1, 1024, 16, 16]         (603,136)\n",
              "│    │    └─Identity: 3-2                     [1, 256, 1024]            --\n",
              "│    └─ModuleList: 2-2                        --                        --\n",
              "│    │    └─NestedTensorBlock: 3-3            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-4            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-5            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-6            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-7            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-8            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-9            [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-10           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-11           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-12           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-13           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-14           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-15           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-16           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-17           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-18           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-19           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-20           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-21           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-22           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-23           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-24           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-25           [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-26           [1, 257, 1024]            (12,598,272)\n",
              "│    └─LayerNorm: 2-3                         [1, 257, 1024]            (2,048)\n",
              "│    └─Identity: 2-4                          [1, 1024]                 --\n",
              "├─Sequential: 1-2                             [1, 8]                    --\n",
              "│    └─Linear: 2-5                            [1, 512]                  524,800\n",
              "│    └─ReLU: 2-6                              [1, 512]                  --\n",
              "│    └─Dropout: 2-7                           [1, 512]                  --\n",
              "│    └─Linear: 2-8                            [1, 8]                    4,104\n",
              "===============================================================================================\n",
              "Total params: 304,897,544\n",
              "Trainable params: 528,904\n",
              "Non-trainable params: 304,368,640\n",
              "Total mult-adds (Units.MEGABYTES): 457.24\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 661.07\n",
              "Params size (MB): 1213.97\n",
              "Estimated Total Size (MB): 1875.65\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model_q, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0baBtuVrans",
        "outputId": "2f9d33ec-5fe1-48df-b877-29bddc087265"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "DINOv2Classifier                                        [1, 8]                    --\n",
              "├─DinoVisionTransformer: 1-1                            [1, 1024]                 1,404,928\n",
              "│    └─PatchEmbed: 2-1                                  [1, 256, 1024]            --\n",
              "│    │    └─QuantConv2d: 3-1                            [1, 1024, 16, 16]         (603,136)\n",
              "│    │    └─Identity: 3-2                               [1, 256, 1024]            --\n",
              "│    └─ModuleList: 2-2                                  --                        --\n",
              "│    │    └─NestedTensorBlock: 3-3                      [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-4                      [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-5                      [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-6                      [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-7                      [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-8                      [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-9                      [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-10                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-11                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-12                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-13                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-14                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-15                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-16                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-17                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-18                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-19                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-20                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-21                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-22                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-23                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-24                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-25                     [1, 257, 1024]            (12,598,272)\n",
              "│    │    └─NestedTensorBlock: 3-26                     [1, 257, 1024]            (12,598,272)\n",
              "│    └─LayerNorm: 2-3                                   [1, 257, 1024]            (2,048)\n",
              "│    └─Identity: 2-4                                    [1, 1024]                 --\n",
              "├─Sequential: 1-2                                       [1, 8]                    --\n",
              "│    └─QuantLinear: 2-5                                 [1, 512]                  524,800\n",
              "│    │    └─TensorQuantizer: 3-27                       [1, 1024]                 --\n",
              "│    │    └─TensorQuantizer: 3-28                       [512, 1024]               --\n",
              "│    │    └─TensorQuantizer: 3-29                       [1, 512]                  --\n",
              "│    └─ReLU: 2-6                                        [1, 512]                  --\n",
              "│    └─Dropout: 2-7                                     [1, 512]                  --\n",
              "│    └─QuantLinear: 2-8                                 [1, 8]                    4,104\n",
              "│    │    └─TensorQuantizer: 3-30                       [1, 512]                  --\n",
              "│    │    └─TensorQuantizer: 3-31                       [8, 512]                  --\n",
              "│    │    └─TensorQuantizer: 3-32                       [1, 8]                    --\n",
              "=========================================================================================================\n",
              "Total params: 304,897,544\n",
              "Trainable params: 528,904\n",
              "Non-trainable params: 304,368,640\n",
              "Total mult-adds (Units.MEGABYTES): 0.10\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 204.22\n",
              "Params size (MB): 0.60\n",
              "Estimated Total Size (MB): 205.42\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNp9Tyd0qbdI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}