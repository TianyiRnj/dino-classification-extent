{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TianyiRnj/dino-classification-extent/blob/Fine_tune/11785_TeamProject_PostTrainingDinoV2HAM10000_MidtermReport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6KQxAuiKIsR"
      },
      "source": [
        "**（1）下载数据集**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M3-WjJPRFcN",
        "outputId": "48de0a1f-f295-466c-e365-aed7c0093cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pandas numpy matplotlib tqdm torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZMhvNp4CZN_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F51wkcYGJaRk"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade kaggle==1.6.17 --force-reinstall --no-deps\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "\n",
        "    f.write('{\"username\":\"\",\"key\":\"\"}')\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxHsJu6ULy1_"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000\n",
        "!unzip -q skin-cancer-mnist-ham10000.zip -d /content/ham10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLk0kYqyL110"
      },
      "outputs": [],
      "source": [
        "# 查看解压后的目录结构\n",
        "import os\n",
        "data_dir = \"/content/ham10000\"\n",
        "print(\"Files in dataset:\", os.listdir(data_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3thX5LdL4EE"
      },
      "outputs": [],
      "source": [
        "# 处理数据目录格式（ImageFolder 需要按类别存放）\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# 读取 metadata（图像-类别映射）\n",
        "metadata = pd.read_csv(os.path.join(data_dir, \"HAM10000_metadata.csv\"))\n",
        "\n",
        "# 创建新的目录结构\n",
        "processed_data_dir = \"/content/ham10000_processed\"\n",
        "os.makedirs(processed_data_dir, exist_ok=True)\n",
        "\n",
        "# 获取所有类别名称\n",
        "categories = metadata[\"dx\"].unique()\n",
        "for category in categories:\n",
        "    os.makedirs(os.path.join(processed_data_dir, category), exist_ok=True)\n",
        "\n",
        "# 归类图片\n",
        "image_dir_1 = os.path.join(data_dir, \"HAM10000_images_part_1\")\n",
        "image_dir_2 = os.path.join(data_dir, \"HAM10000_images_part_2\")\n",
        "\n",
        "for _, row in metadata.iterrows():\n",
        "    image_id = row[\"image_id\"]\n",
        "    category = row[\"dx\"]\n",
        "    src_path = None\n",
        "\n",
        "    if os.path.exists(os.path.join(image_dir_1, f\"{image_id}.jpg\")):\n",
        "        src_path = os.path.join(image_dir_1, f\"{image_id}.jpg\")\n",
        "    elif os.path.exists(os.path.join(image_dir_2, f\"{image_id}.jpg\")):\n",
        "        src_path = os.path.join(image_dir_2, f\"{image_id}.jpg\")\n",
        "\n",
        "    if src_path:\n",
        "        dst_path = os.path.join(processed_data_dir, category, f\"{image_id}.jpg\")\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(\"数据已整理完毕！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1ypxqRlKCy7"
      },
      "source": [
        "**(2) 数据预处理**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_83Y0EcFKAL_"
      },
      "outputs": [],
      "source": [
        "# 使用 ImageFolder 读取数据\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "# 数据预处理\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # DINOv2 需要 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# 指定数据存放路径\n",
        "processed_data_dir = \"/content/ham10000_processed\"\n",
        "\n",
        "# 读取数据\n",
        "dataset = ImageFolder(root=processed_data_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 输出数据集信息\n",
        "print(f\"Dataset loaded with {len(dataset)} images\")\n",
        "print(f\"Classes: {dataset.classes}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWgenNM8KQLs"
      },
      "source": [
        "**（3）加载 DINOv2 进行 Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import Dinov2Model\n",
        "\n",
        "class DINOv2Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=8, pretrain_choice='frozen'):\n",
        "        super().__init__()\n",
        "\n",
        "        # 加载 DINOv2 预训练模型\n",
        "        self.dinov2 = Dinov2Model.from_pretrained(\"facebook/dinov2-base\")\n",
        "\n",
        "        # 是否冻结 DINOv2 的参数\n",
        "        if pretrain_choice == 'frozen':\n",
        "            for param in self.dinov2.parameters():\n",
        "                param.requires_grad = False  # 冻结 DINOv2 权重\n",
        "\n",
        "        # 分类器\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.dinov2.config.hidden_size, 512),  # DINOv2 输出维度\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 提取特征 (batch_size, num_patches, hidden_dim)\n",
        "        features = self.dinov2(x).last_hidden_state\n",
        "\n",
        "        # 取 [CLS] token 作为分类输入 (batch_size, hidden_dim)\n",
        "        cls_token = features[:, 0, :]\n",
        "\n",
        "        # 通过分类器\n",
        "        out = self.classifier(cls_token)\n",
        "        return out\n",
        "\n",
        "# 设备选择\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 加载模型\n",
        "model = DINOv2Classifier(pretrain_choice='frozen').to(device)\n",
        "\n",
        "# 打印模型摘要\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 224, 224))\n"
      ],
      "metadata": {
        "id": "s9d5IsL0JQbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6z97V9eKjSP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def extract_features(model, images, device=\"cuda\"):\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(images)  # DINOv2 GitHub 版\n",
        "        print(\"Model Output Shape:\", output.shape)\n",
        "\n",
        "        if output.dim() == 2:\n",
        "            return output\n",
        "        elif output.dim() == 3:\n",
        "            return output[:, 0, :]\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected model output shape: {output.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQS9xOqggZFK"
      },
      "outputs": [],
      "source": [
        "for batch in dataloader:\n",
        "    print(type(batch), len(batch))  # 检查 batch 数据格式\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bbNffPwglQn"
      },
      "outputs": [],
      "source": [
        "for batch in dataloader:\n",
        "    print(\"Batch Type:\", type(batch))\n",
        "    print(\"Batch Length:\", len(batch))\n",
        "    print(\"Type of batch[0]:\", type(batch[0]))  # 检查 images\n",
        "    print(\"Type of batch[1]:\", type(batch[1]))  # 检查 labels\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TuSrMLOgqz9"
      },
      "outputs": [],
      "source": [
        "for batch in dataloader:\n",
        "    images, labels = batch[0], batch[1]  # 解包\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Freeze**"
      ],
      "metadata": {
        "id": "gLJt6I8-TcLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModel\n",
        "\n",
        "# 加载 DINOv2 预训练模型\n",
        "dino_model = AutoModel.from_pretrained(\"facebook/dino-v2-base\")\n",
        "\n",
        "# 冻结所有层\n",
        "for param in dino_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 选择解冻\n",
        "for i in range(-3, 0):  # 解冻最后 3 层\n",
        "    for param in dino_model.encoder.layer[i].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "print(\"解冻的层：\", [name for name, param in dino_model.named_parameters() if param.requires_grad])\n"
      ],
      "metadata": {
        "id": "kdwgAlYOTSRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义 Fine-tuned DINOv2 模型\n",
        "class FineTunedDINOv2(nn.Module):\n",
        "    def __init__(self, base_model, num_classes):\n",
        "        super(FineTunedDINOv2, self).__init__()\n",
        "        self.dino = base_model\n",
        "        self.fc = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.dino(x).last_hidden_state[:, 0, :]\n",
        "        output = self.fc(features)\n",
        "        return output\n",
        "\n",
        "# 实例化模型\n",
        "num_classes = 7\n",
        "model = FineTunedDINOv2(dino_model, num_classes)\n",
        "\n",
        "# 选择要训练的参数\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "print(f\"需要训练的参数量: {sum(p.numel() for p in trainable_params)}\")\n"
      ],
      "metadata": {
        "id": "BAlJZXkmTUgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练参数\n",
        "learning_rate = 1e-5\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "# 选择优化器\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate)\n",
        "\n",
        "# 交叉熵损失\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 训练数据\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "dataset = ImageFolder(root=\"/content/ham10000_processed\", transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "B6w_5H7bTXzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n"
      ],
      "metadata": {
        "id": "9N7BJbpFTZZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(f\"Test Accuracy: {correct / total:.4f}\")\n"
      ],
      "metadata": {
        "id": "gwsfXPOcTh_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPxX/9YcPQjyc2T56G2mKEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}