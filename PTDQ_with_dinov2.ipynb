{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TianyiRnj/dino-classification-extent/blob/main/PTDQ_with_dinov2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l1SzyWjzjhqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d75bb86-6766-46f2-a86a-b1486646eed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pandas numpy matplotlib tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo --quiet"
      ],
      "metadata": {
        "id": "5yHq_0kUnEkA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zruaxu6jlhUQ",
        "outputId": "b0057833-f034-4d6f-b332-88e9be34d98b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/487.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/487.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "uvIBd2bsegY4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment this if you want to use Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "%cd /content/gdrive/MyDrive/11785/DL_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FmQ0lPsX-wI",
        "outputId": "13d71ac3-97f4-42ba-894d-17eaf4799764"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/11785/DL_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "!kaggle datasets download andrewmvd/isic-2019\n",
        "!unzip -q isic-2019.zip -d '/content/sample_data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z6HP5mVj6Kc",
        "outputId": "ec97f8ae-ad3f-422d-bfa7-18509b7f0138"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/isic-2019\n",
            "License(s): Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
            "isic-2019.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "structure: 'normclassi'\n",
        "num_epochs: 20\n",
        "wandb: False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGZ2uiK4YqQd",
        "outputId": "dd9f8af8-6dc4-4889-fbac-13ffde2a41f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "with open(\"config.yaml\") as file:\n",
        "    config = yaml.safe_load(file)\n",
        "print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ovT0DjiYtSj",
        "outputId": "dba8f8ca-f40c-4510-c8ae-08ddde84a238"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'structure': 'normclassi', 'num_epochs': 20, 'wandb': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECKPOINT"
      ],
      "metadata": {
        "id": "GTf-y4mOc3AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESUME_TRAINING = True\n",
        "PRE_CHECKPOINTS_PATH = f'/content/gdrive/MyDrive/11785/DL_project/checkpoints-basic/checkpoint-best-model.pth'\n",
        "CHECKPOINTS_ROOT = f\"/content/gdrive/MyDrive/11785/DL_project/checkpoints-PTQ\"\n",
        "os.makedirs(CHECKPOINTS_ROOT, exist_ok=True)\n",
        "DATA_ROOT = '/content/sample_data'"
      ],
      "metadata": {
        "id": "FqgpWOBJcgYw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORGANIZE DATA"
      ],
      "metadata": {
        "id": "u978BeKvch8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Organize Data ---\n",
        "# Load metadata\n",
        "train_meta = pd.read_csv(f\"{DATA_ROOT}/ISIC_2019_Training_GroundTruth.csv\")\n",
        "train_meta['image'] = train_meta['image'] + '.jpg'\n",
        "\n",
        "# Convert one-hot encoding to class labels\n",
        "classes = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n",
        "train_meta['label'] = train_meta[classes].idxmax(axis=1)\n",
        "label_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n"
      ],
      "metadata": {
        "id": "OfIr73lyeh3A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(train_meta, test_size=0.3,\n",
        "                                    stratify=train_meta['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5,\n",
        "                                  stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "# --- Step 3: Define Dataset Class ---\n",
        "class ISIC2019Dataset(Dataset):\n",
        "    def __init__(self, df, img_dir=f'{DATA_ROOT}/ISIC_2019_Training_Input/ISIC_2019_Training_Input', transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.label_to_idx = label_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.df.iloc[idx]['image'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.label_to_idx[self.df.iloc[idx]['label']]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "4oYEH2aBj7xD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Data Transforms and Loaders ---\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create datasets and loaders\n",
        "batch_size = 64\n",
        "train_dataset = ISIC2019Dataset(train_df, transform=train_transform)\n",
        "val_dataset = ISIC2019Dataset(val_df, transform=val_transform)\n",
        "test_dataset = ISIC2019Dataset(test_df, transform=val_transform)\n",
        "\n",
        "workers = os.cpu_count()\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)"
      ],
      "metadata": {
        "id": "Fshz4BxQj95f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Model Setup ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Step 5: Handle Class Imbalance ---\n",
        "train_labels = [label for _, label in train_dataset]\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
      ],
      "metadata": {
        "id": "zIG4o9GAfVYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a457aad-bc7c-48b8-f676-ad0531f34b67"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "\n",
        "class DINOv2Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=8, pretrain_choice='frozen'):\n",
        "        super().__init__()\n",
        "        self.dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.dinov2.embed_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get all image features (batch_size, num_patches, embed_dim)\n",
        "        features = self.dinov2(x)\n",
        "        features = self.dinov2.norm(features)\n",
        "\n",
        "        # Handle different output formats:\n",
        "        if features.dim() == 3:  # Standard case with spatial dimensions\n",
        "            cls_token = features[:, 0, :]  # Extract [CLS] token\n",
        "\n",
        "        else:  # Fallback for 2D output\n",
        "            cls_token = features\n",
        "\n",
        "        out = self.classifier(cls_token)\n",
        "        return out\n",
        "\n",
        "# model = DINOv2Classifier().to(device)\n",
        "model = DINOv2Classifier(pretrain_choice='frozen').to(device)\n",
        "summary(model, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYjSSyvtj_G6",
        "outputId": "4c283ea1-4224-49f8-8fad-808c69c6c6f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vits14/dinov2_vits14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vits14_pretrain.pth\n",
            "100%|██████████| 84.2M/84.2M [00:00<00:00, 111MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 384, 16, 16]         226,176\n",
            "          Identity-2             [-1, 256, 384]               0\n",
            "        PatchEmbed-3             [-1, 256, 384]               0\n",
            "         LayerNorm-4             [-1, 257, 384]             768\n",
            "            Linear-5            [-1, 257, 1152]         443,520\n",
            "           Dropout-6          [-1, 6, 257, 257]               0\n",
            "            Linear-7             [-1, 257, 384]         147,840\n",
            "           Dropout-8             [-1, 257, 384]               0\n",
            "   MemEffAttention-9             [-1, 257, 384]               0\n",
            "       LayerScale-10             [-1, 257, 384]               0\n",
            "        LayerNorm-11             [-1, 257, 384]             768\n",
            "           Linear-12            [-1, 257, 1536]         591,360\n",
            "             GELU-13            [-1, 257, 1536]               0\n",
            "          Dropout-14            [-1, 257, 1536]               0\n",
            "           Linear-15             [-1, 257, 384]         590,208\n",
            "          Dropout-16             [-1, 257, 384]               0\n",
            "              Mlp-17             [-1, 257, 384]               0\n",
            "       LayerScale-18             [-1, 257, 384]               0\n",
            "NestedTensorBlock-19             [-1, 257, 384]               0\n",
            "        LayerNorm-20             [-1, 257, 384]             768\n",
            "           Linear-21            [-1, 257, 1152]         443,520\n",
            "          Dropout-22          [-1, 6, 257, 257]               0\n",
            "           Linear-23             [-1, 257, 384]         147,840\n",
            "          Dropout-24             [-1, 257, 384]               0\n",
            "  MemEffAttention-25             [-1, 257, 384]               0\n",
            "       LayerScale-26             [-1, 257, 384]               0\n",
            "        LayerNorm-27             [-1, 257, 384]             768\n",
            "           Linear-28            [-1, 257, 1536]         591,360\n",
            "             GELU-29            [-1, 257, 1536]               0\n",
            "          Dropout-30            [-1, 257, 1536]               0\n",
            "           Linear-31             [-1, 257, 384]         590,208\n",
            "          Dropout-32             [-1, 257, 384]               0\n",
            "              Mlp-33             [-1, 257, 384]               0\n",
            "       LayerScale-34             [-1, 257, 384]               0\n",
            "NestedTensorBlock-35             [-1, 257, 384]               0\n",
            "        LayerNorm-36             [-1, 257, 384]             768\n",
            "           Linear-37            [-1, 257, 1152]         443,520\n",
            "          Dropout-38          [-1, 6, 257, 257]               0\n",
            "           Linear-39             [-1, 257, 384]         147,840\n",
            "          Dropout-40             [-1, 257, 384]               0\n",
            "  MemEffAttention-41             [-1, 257, 384]               0\n",
            "       LayerScale-42             [-1, 257, 384]               0\n",
            "        LayerNorm-43             [-1, 257, 384]             768\n",
            "           Linear-44            [-1, 257, 1536]         591,360\n",
            "             GELU-45            [-1, 257, 1536]               0\n",
            "          Dropout-46            [-1, 257, 1536]               0\n",
            "           Linear-47             [-1, 257, 384]         590,208\n",
            "          Dropout-48             [-1, 257, 384]               0\n",
            "              Mlp-49             [-1, 257, 384]               0\n",
            "       LayerScale-50             [-1, 257, 384]               0\n",
            "NestedTensorBlock-51             [-1, 257, 384]               0\n",
            "        LayerNorm-52             [-1, 257, 384]             768\n",
            "           Linear-53            [-1, 257, 1152]         443,520\n",
            "          Dropout-54          [-1, 6, 257, 257]               0\n",
            "           Linear-55             [-1, 257, 384]         147,840\n",
            "          Dropout-56             [-1, 257, 384]               0\n",
            "  MemEffAttention-57             [-1, 257, 384]               0\n",
            "       LayerScale-58             [-1, 257, 384]               0\n",
            "        LayerNorm-59             [-1, 257, 384]             768\n",
            "           Linear-60            [-1, 257, 1536]         591,360\n",
            "             GELU-61            [-1, 257, 1536]               0\n",
            "          Dropout-62            [-1, 257, 1536]               0\n",
            "           Linear-63             [-1, 257, 384]         590,208\n",
            "          Dropout-64             [-1, 257, 384]               0\n",
            "              Mlp-65             [-1, 257, 384]               0\n",
            "       LayerScale-66             [-1, 257, 384]               0\n",
            "NestedTensorBlock-67             [-1, 257, 384]               0\n",
            "        LayerNorm-68             [-1, 257, 384]             768\n",
            "           Linear-69            [-1, 257, 1152]         443,520\n",
            "          Dropout-70          [-1, 6, 257, 257]               0\n",
            "           Linear-71             [-1, 257, 384]         147,840\n",
            "          Dropout-72             [-1, 257, 384]               0\n",
            "  MemEffAttention-73             [-1, 257, 384]               0\n",
            "       LayerScale-74             [-1, 257, 384]               0\n",
            "        LayerNorm-75             [-1, 257, 384]             768\n",
            "           Linear-76            [-1, 257, 1536]         591,360\n",
            "             GELU-77            [-1, 257, 1536]               0\n",
            "          Dropout-78            [-1, 257, 1536]               0\n",
            "           Linear-79             [-1, 257, 384]         590,208\n",
            "          Dropout-80             [-1, 257, 384]               0\n",
            "              Mlp-81             [-1, 257, 384]               0\n",
            "       LayerScale-82             [-1, 257, 384]               0\n",
            "NestedTensorBlock-83             [-1, 257, 384]               0\n",
            "        LayerNorm-84             [-1, 257, 384]             768\n",
            "           Linear-85            [-1, 257, 1152]         443,520\n",
            "          Dropout-86          [-1, 6, 257, 257]               0\n",
            "           Linear-87             [-1, 257, 384]         147,840\n",
            "          Dropout-88             [-1, 257, 384]               0\n",
            "  MemEffAttention-89             [-1, 257, 384]               0\n",
            "       LayerScale-90             [-1, 257, 384]               0\n",
            "        LayerNorm-91             [-1, 257, 384]             768\n",
            "           Linear-92            [-1, 257, 1536]         591,360\n",
            "             GELU-93            [-1, 257, 1536]               0\n",
            "          Dropout-94            [-1, 257, 1536]               0\n",
            "           Linear-95             [-1, 257, 384]         590,208\n",
            "          Dropout-96             [-1, 257, 384]               0\n",
            "              Mlp-97             [-1, 257, 384]               0\n",
            "       LayerScale-98             [-1, 257, 384]               0\n",
            "NestedTensorBlock-99             [-1, 257, 384]               0\n",
            "       LayerNorm-100             [-1, 257, 384]             768\n",
            "          Linear-101            [-1, 257, 1152]         443,520\n",
            "         Dropout-102          [-1, 6, 257, 257]               0\n",
            "          Linear-103             [-1, 257, 384]         147,840\n",
            "         Dropout-104             [-1, 257, 384]               0\n",
            " MemEffAttention-105             [-1, 257, 384]               0\n",
            "      LayerScale-106             [-1, 257, 384]               0\n",
            "       LayerNorm-107             [-1, 257, 384]             768\n",
            "          Linear-108            [-1, 257, 1536]         591,360\n",
            "            GELU-109            [-1, 257, 1536]               0\n",
            "         Dropout-110            [-1, 257, 1536]               0\n",
            "          Linear-111             [-1, 257, 384]         590,208\n",
            "         Dropout-112             [-1, 257, 384]               0\n",
            "             Mlp-113             [-1, 257, 384]               0\n",
            "      LayerScale-114             [-1, 257, 384]               0\n",
            "NestedTensorBlock-115             [-1, 257, 384]               0\n",
            "       LayerNorm-116             [-1, 257, 384]             768\n",
            "          Linear-117            [-1, 257, 1152]         443,520\n",
            "         Dropout-118          [-1, 6, 257, 257]               0\n",
            "          Linear-119             [-1, 257, 384]         147,840\n",
            "         Dropout-120             [-1, 257, 384]               0\n",
            " MemEffAttention-121             [-1, 257, 384]               0\n",
            "      LayerScale-122             [-1, 257, 384]               0\n",
            "       LayerNorm-123             [-1, 257, 384]             768\n",
            "          Linear-124            [-1, 257, 1536]         591,360\n",
            "            GELU-125            [-1, 257, 1536]               0\n",
            "         Dropout-126            [-1, 257, 1536]               0\n",
            "          Linear-127             [-1, 257, 384]         590,208\n",
            "         Dropout-128             [-1, 257, 384]               0\n",
            "             Mlp-129             [-1, 257, 384]               0\n",
            "      LayerScale-130             [-1, 257, 384]               0\n",
            "NestedTensorBlock-131             [-1, 257, 384]               0\n",
            "       LayerNorm-132             [-1, 257, 384]             768\n",
            "          Linear-133            [-1, 257, 1152]         443,520\n",
            "         Dropout-134          [-1, 6, 257, 257]               0\n",
            "          Linear-135             [-1, 257, 384]         147,840\n",
            "         Dropout-136             [-1, 257, 384]               0\n",
            " MemEffAttention-137             [-1, 257, 384]               0\n",
            "      LayerScale-138             [-1, 257, 384]               0\n",
            "       LayerNorm-139             [-1, 257, 384]             768\n",
            "          Linear-140            [-1, 257, 1536]         591,360\n",
            "            GELU-141            [-1, 257, 1536]               0\n",
            "         Dropout-142            [-1, 257, 1536]               0\n",
            "          Linear-143             [-1, 257, 384]         590,208\n",
            "         Dropout-144             [-1, 257, 384]               0\n",
            "             Mlp-145             [-1, 257, 384]               0\n",
            "      LayerScale-146             [-1, 257, 384]               0\n",
            "NestedTensorBlock-147             [-1, 257, 384]               0\n",
            "       LayerNorm-148             [-1, 257, 384]             768\n",
            "          Linear-149            [-1, 257, 1152]         443,520\n",
            "         Dropout-150          [-1, 6, 257, 257]               0\n",
            "          Linear-151             [-1, 257, 384]         147,840\n",
            "         Dropout-152             [-1, 257, 384]               0\n",
            " MemEffAttention-153             [-1, 257, 384]               0\n",
            "      LayerScale-154             [-1, 257, 384]               0\n",
            "       LayerNorm-155             [-1, 257, 384]             768\n",
            "          Linear-156            [-1, 257, 1536]         591,360\n",
            "            GELU-157            [-1, 257, 1536]               0\n",
            "         Dropout-158            [-1, 257, 1536]               0\n",
            "          Linear-159             [-1, 257, 384]         590,208\n",
            "         Dropout-160             [-1, 257, 384]               0\n",
            "             Mlp-161             [-1, 257, 384]               0\n",
            "      LayerScale-162             [-1, 257, 384]               0\n",
            "NestedTensorBlock-163             [-1, 257, 384]               0\n",
            "       LayerNorm-164             [-1, 257, 384]             768\n",
            "          Linear-165            [-1, 257, 1152]         443,520\n",
            "         Dropout-166          [-1, 6, 257, 257]               0\n",
            "          Linear-167             [-1, 257, 384]         147,840\n",
            "         Dropout-168             [-1, 257, 384]               0\n",
            " MemEffAttention-169             [-1, 257, 384]               0\n",
            "      LayerScale-170             [-1, 257, 384]               0\n",
            "       LayerNorm-171             [-1, 257, 384]             768\n",
            "          Linear-172            [-1, 257, 1536]         591,360\n",
            "            GELU-173            [-1, 257, 1536]               0\n",
            "         Dropout-174            [-1, 257, 1536]               0\n",
            "          Linear-175             [-1, 257, 384]         590,208\n",
            "         Dropout-176             [-1, 257, 384]               0\n",
            "             Mlp-177             [-1, 257, 384]               0\n",
            "      LayerScale-178             [-1, 257, 384]               0\n",
            "NestedTensorBlock-179             [-1, 257, 384]               0\n",
            "       LayerNorm-180             [-1, 257, 384]             768\n",
            "          Linear-181            [-1, 257, 1152]         443,520\n",
            "         Dropout-182          [-1, 6, 257, 257]               0\n",
            "          Linear-183             [-1, 257, 384]         147,840\n",
            "         Dropout-184             [-1, 257, 384]               0\n",
            " MemEffAttention-185             [-1, 257, 384]               0\n",
            "      LayerScale-186             [-1, 257, 384]               0\n",
            "       LayerNorm-187             [-1, 257, 384]             768\n",
            "          Linear-188            [-1, 257, 1536]         591,360\n",
            "            GELU-189            [-1, 257, 1536]               0\n",
            "         Dropout-190            [-1, 257, 1536]               0\n",
            "          Linear-191             [-1, 257, 384]         590,208\n",
            "         Dropout-192             [-1, 257, 384]               0\n",
            "             Mlp-193             [-1, 257, 384]               0\n",
            "      LayerScale-194             [-1, 257, 384]               0\n",
            "NestedTensorBlock-195             [-1, 257, 384]               0\n",
            "       LayerNorm-196             [-1, 257, 384]             768\n",
            "        Identity-197                  [-1, 384]               0\n",
            "DinoVisionTransformer-198                  [-1, 384]               0\n",
            "       LayerNorm-199                  [-1, 384]             768\n",
            "          Linear-200                  [-1, 512]         197,120\n",
            "            ReLU-201                  [-1, 512]               0\n",
            "         Dropout-202                  [-1, 512]               0\n",
            "          Linear-203                    [-1, 8]           4,104\n",
            "================================================================\n",
            "Total params: 21,722,504\n",
            "Trainable params: 21,722,504\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 274.22\n",
            "Params size (MB): 82.86\n",
            "Estimated Total Size (MB): 357.66\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL SAVE"
      ],
      "metadata": {
        "id": "kw1msP7ie0pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    torch.save(\n",
        "        {'model_state_dict'         : model.state_dict(),\n",
        "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'     : scheduler.state_dict() if scheduler is not None else {},\n",
        "         metric[0]                  : metric[1],\n",
        "         'epoch'                    : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, optimizer= None, scheduler= None, metric='valid_dist'):\n",
        "\n",
        "    checkpoint = torch.load(path, map_location=torch.device(device))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer != None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler != None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch   = checkpoint['epoch']\n",
        "    metric  = checkpoint[metric]\n",
        "\n",
        "    print(\"\\nResuming training from epoch:\", epoch)\n",
        "    print('----------------------------------------\\n')\n",
        "    print(\"Epochs left: \", config['num_epochs'] - epoch)\n",
        "    print(\"Optimizer: \\n\", optimizer)\n",
        "    # print(\"Current Schedueler T_cur:\", scheduler.T_cur)\n",
        "\n",
        "    print(\"Best Val Dist:\", metric)\n",
        "\n",
        "    return [model, optimizer, scheduler, epoch, metric]"
      ],
      "metadata": {
        "id": "7UDdmtnGe2ao"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-6, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)"
      ],
      "metadata": {
        "id": "xm-d6ERJkBZx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WANDB"
      ],
      "metadata": {
        "id": "EUGHC6MccQg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "# Uncomment to use wandb\n",
        "if config['wandb']:\n",
        "    wandb.login(key=\"1311b018830e3a64af503c0903514d9827af68eb\")\n",
        "    run = wandb.init(\n",
        "        name=f\"dinov2_{config['structure']}\",\n",
        "        entity=\"11789-dino-project-team-48\",\n",
        "        project='11785-DL-project',\n",
        "\n",
        "        config=config,\n",
        "        reinit=False\n",
        "    )\n",
        "\n",
        "    #Save model in a txt file\n",
        "    model_arch  = str(model)\n",
        "    arch_file   = open(\"model_arch.txt\", \"w\")\n",
        "    file_write  = arch_file.write(model_arch)\n",
        "    arch_file.close()\n",
        "\n",
        "    # Use wandb.Artifact to log the file\n",
        "    artifact = wandb.Artifact('model_arch', type='model')\n",
        "    artifact.add_file('model_arch.txt')\n",
        "    wandb.log_artifact(artifact)\n",
        "\n",
        "    wandb.watch(model, log=\"all\")"
      ],
      "metadata": {
        "id": "L9wTSvUAaBAn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIAL CHECKPOINTS"
      ],
      "metadata": {
        "id": "4B6FwFpLdPYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_epoch_completed = 0\n",
        "best_lev_dist = float(\"inf\")\n",
        "\n",
        "if RESUME_TRAINING:\n",
        "    [model, optimizer, scheduler, epoch, metric] = load_model(PRE_CHECKPOINTS_PATH, model, optimizer, scheduler, metric='val_acc')\n",
        "\n",
        "    last_epoch_completed = epoch\n",
        "    best_lev_dist = metric"
      ],
      "metadata": {
        "id": "xCrU0BHbfu9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88ef161-9201-44b5-ba93-803659ed1322"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resuming training from epoch: 26\n",
            "----------------------------------------\n",
            "\n",
            "Epochs left:  -6\n",
            "Optimizer: \n",
            " AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 1.25e-07\n",
            "    maximize: False\n",
            "    weight_decay: 0.0001\n",
            ")\n",
            "Best Val Dist: 0.7547368421052632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_best_model_filename = 'checkpoint-best-model.pth'\n",
        "checkpoint_last_epoch_filename = 'checkpoint-last-epoch.pth'\n",
        "epoch_model_path = os.path.join(CHECKPOINTS_ROOT, checkpoint_last_epoch_filename)\n",
        "best_model_path = os.path.join(CHECKPOINTS_ROOT, checkpoint_best_model_filename)"
      ],
      "metadata": {
        "id": "SYevALN5cO3H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Training"
      ],
      "metadata": {
        "id": "aL9M_t2YfyWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "# Clear RAM for storage before you start training\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "thsTMpMvdNXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb551f65-dc8e-426d-eba7-ef44d026bd49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = 0.0\n",
        "\n",
        "# Lists to store metrics for plotting\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "\n",
        "for epoch in range(last_epoch_completed, config['num_epochs']):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=True)\n",
        "\n",
        "    for images, labels in train_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        train_loop.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Val]\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loop.set_postfix({\n",
        "                'loss': f\"{loss.item():.4f}\",\n",
        "                'acc': f\"{correct/total:.4f}\"\n",
        "            })\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = correct / total\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    save_model(model, optimizer, scheduler, ['val_acc', val_acc], epoch, epoch_model_path)\n",
        "    if config['wandb']:\n",
        "        wandb.log({\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_acc\": val_acc,\n",
        "            \"lr\": optimizer.param_groups[0]['lr']\n",
        "        })\n",
        "        artifact_epoch = wandb.Artifact(f'epoch_model_{epoch}', type='model')\n",
        "        artifact_epoch.add_file(epoch_model_path)\n",
        "        wandb.log_artifact(artifact_epoch)\n",
        "    print('Saving model...')\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        save_model(model, optimizer, scheduler, ['val_acc', val_acc], epoch, best_model_path)\n",
        "        if config['wandb']:\n",
        "            artifact_best = wandb.Artifact('best_model', type='model')\n",
        "            artifact_best.add_file(best_model_path)\n",
        "            wandb.log_artifact(artifact_best)\n",
        "        print(f\"\\nNew best model saved with val acc: {val_acc:.4f}\")\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "if config['wandb']:\n",
        "    run.finish()"
      ],
      "metadata": {
        "id": "8efHFigmkCZL",
        "collapsed": true
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if train_losses and val_losses and val_accs:\n",
        "    # Plotting the metrics after training\n",
        "    epochs = range(last_epoch_completed, config['num_epochs'])\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot Train and Validation Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs, val_losses, label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Train & Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Validation Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, val_accs, label='Val Accuracy', color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Gjf9-se53RwX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 9: Final Evaluation ---\n",
        "# model.load_state_dict(torch.load(best_model_path)['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "test_loop = tqdm(test_loader, desc='Testing', leave=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loop.set_postfix({'acc': f\"{test_correct/test_total:.4f}\"})\n",
        "\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "2OhxD4SykFKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aafb66c-e29c-4a30-e202-da19405ab63e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 60/60 [21:11<00:00, 21.20s/it, acc=0.7455]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy: 0.7455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post Training Dynamic Quantization"
      ],
      "metadata": {
        "id": "sZ1xdCtzDVVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantizedDINOv2Classifier(nn.Module):\n",
        "    def __init__(self, dinov2_model, quantized_classifier):\n",
        "        super().__init__()\n",
        "        self.dinov2 = dinov2_model\n",
        "        self.classifier = quantized_classifier\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.dinov2(x)\n",
        "        features = self.dinov2.norm(features)\n",
        "        return self.classifier(features)\n",
        "\n",
        "quantized_dinov2 = torch.quantization.quantize_dynamic(\n",
        "    model.dinov2, {nn.Linear}, dtype=torch.qint8\n",
        ").to('cpu')\n",
        "\n",
        "quantized_classifier = torch.quantization.quantize_dynamic(\n",
        "    model.classifier, {nn.Linear}, dtype=torch.qint8\n",
        ").to('cpu')\n",
        "\n",
        "quantized_model = QuantizedDINOv2Classifier(quantized_dinov2, quantized_classifier).to(\"cpu\")\n",
        "summary(quantized_model, input_size=(3, 224, 224))\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "test_loop = tqdm(test_loader, desc='Testing Quantized Model', leave=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loop:\n",
        "        images, labels = images.to('cpu'), labels.to('cpu')\n",
        "        outputs = quantized_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loop.set_postfix({'acc': f\"{test_correct/test_total:.4f}\"})\n",
        "\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "jYnIaZnSDU2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555d17dc-fb4c-400a-c2c3-b0040a885c74"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 384, 16, 16]         226,176\n",
            "          Identity-2             [-1, 256, 384]               0\n",
            "        PatchEmbed-3             [-1, 256, 384]               0\n",
            "         LayerNorm-4             [-1, 257, 384]             768\n",
            "            Linear-5            [-1, 257, 1152]               0\n",
            "           Dropout-6          [-1, 6, 257, 257]               0\n",
            "            Linear-7             [-1, 257, 384]               0\n",
            "           Dropout-8             [-1, 257, 384]               0\n",
            "   MemEffAttention-9             [-1, 257, 384]               0\n",
            "       LayerScale-10             [-1, 257, 384]               0\n",
            "        LayerNorm-11             [-1, 257, 384]             768\n",
            "           Linear-12            [-1, 257, 1536]               0\n",
            "             GELU-13            [-1, 257, 1536]               0\n",
            "          Dropout-14            [-1, 257, 1536]               0\n",
            "           Linear-15             [-1, 257, 384]               0\n",
            "          Dropout-16             [-1, 257, 384]               0\n",
            "              Mlp-17             [-1, 257, 384]               0\n",
            "       LayerScale-18             [-1, 257, 384]               0\n",
            "NestedTensorBlock-19             [-1, 257, 384]               0\n",
            "        LayerNorm-20             [-1, 257, 384]             768\n",
            "           Linear-21            [-1, 257, 1152]               0\n",
            "          Dropout-22          [-1, 6, 257, 257]               0\n",
            "           Linear-23             [-1, 257, 384]               0\n",
            "          Dropout-24             [-1, 257, 384]               0\n",
            "  MemEffAttention-25             [-1, 257, 384]               0\n",
            "       LayerScale-26             [-1, 257, 384]               0\n",
            "        LayerNorm-27             [-1, 257, 384]             768\n",
            "           Linear-28            [-1, 257, 1536]               0\n",
            "             GELU-29            [-1, 257, 1536]               0\n",
            "          Dropout-30            [-1, 257, 1536]               0\n",
            "           Linear-31             [-1, 257, 384]               0\n",
            "          Dropout-32             [-1, 257, 384]               0\n",
            "              Mlp-33             [-1, 257, 384]               0\n",
            "       LayerScale-34             [-1, 257, 384]               0\n",
            "NestedTensorBlock-35             [-1, 257, 384]               0\n",
            "        LayerNorm-36             [-1, 257, 384]             768\n",
            "           Linear-37            [-1, 257, 1152]               0\n",
            "          Dropout-38          [-1, 6, 257, 257]               0\n",
            "           Linear-39             [-1, 257, 384]               0\n",
            "          Dropout-40             [-1, 257, 384]               0\n",
            "  MemEffAttention-41             [-1, 257, 384]               0\n",
            "       LayerScale-42             [-1, 257, 384]               0\n",
            "        LayerNorm-43             [-1, 257, 384]             768\n",
            "           Linear-44            [-1, 257, 1536]               0\n",
            "             GELU-45            [-1, 257, 1536]               0\n",
            "          Dropout-46            [-1, 257, 1536]               0\n",
            "           Linear-47             [-1, 257, 384]               0\n",
            "          Dropout-48             [-1, 257, 384]               0\n",
            "              Mlp-49             [-1, 257, 384]               0\n",
            "       LayerScale-50             [-1, 257, 384]               0\n",
            "NestedTensorBlock-51             [-1, 257, 384]               0\n",
            "        LayerNorm-52             [-1, 257, 384]             768\n",
            "           Linear-53            [-1, 257, 1152]               0\n",
            "          Dropout-54          [-1, 6, 257, 257]               0\n",
            "           Linear-55             [-1, 257, 384]               0\n",
            "          Dropout-56             [-1, 257, 384]               0\n",
            "  MemEffAttention-57             [-1, 257, 384]               0\n",
            "       LayerScale-58             [-1, 257, 384]               0\n",
            "        LayerNorm-59             [-1, 257, 384]             768\n",
            "           Linear-60            [-1, 257, 1536]               0\n",
            "             GELU-61            [-1, 257, 1536]               0\n",
            "          Dropout-62            [-1, 257, 1536]               0\n",
            "           Linear-63             [-1, 257, 384]               0\n",
            "          Dropout-64             [-1, 257, 384]               0\n",
            "              Mlp-65             [-1, 257, 384]               0\n",
            "       LayerScale-66             [-1, 257, 384]               0\n",
            "NestedTensorBlock-67             [-1, 257, 384]               0\n",
            "        LayerNorm-68             [-1, 257, 384]             768\n",
            "           Linear-69            [-1, 257, 1152]               0\n",
            "          Dropout-70          [-1, 6, 257, 257]               0\n",
            "           Linear-71             [-1, 257, 384]               0\n",
            "          Dropout-72             [-1, 257, 384]               0\n",
            "  MemEffAttention-73             [-1, 257, 384]               0\n",
            "       LayerScale-74             [-1, 257, 384]               0\n",
            "        LayerNorm-75             [-1, 257, 384]             768\n",
            "           Linear-76            [-1, 257, 1536]               0\n",
            "             GELU-77            [-1, 257, 1536]               0\n",
            "          Dropout-78            [-1, 257, 1536]               0\n",
            "           Linear-79             [-1, 257, 384]               0\n",
            "          Dropout-80             [-1, 257, 384]               0\n",
            "              Mlp-81             [-1, 257, 384]               0\n",
            "       LayerScale-82             [-1, 257, 384]               0\n",
            "NestedTensorBlock-83             [-1, 257, 384]               0\n",
            "        LayerNorm-84             [-1, 257, 384]             768\n",
            "           Linear-85            [-1, 257, 1152]               0\n",
            "          Dropout-86          [-1, 6, 257, 257]               0\n",
            "           Linear-87             [-1, 257, 384]               0\n",
            "          Dropout-88             [-1, 257, 384]               0\n",
            "  MemEffAttention-89             [-1, 257, 384]               0\n",
            "       LayerScale-90             [-1, 257, 384]               0\n",
            "        LayerNorm-91             [-1, 257, 384]             768\n",
            "           Linear-92            [-1, 257, 1536]               0\n",
            "             GELU-93            [-1, 257, 1536]               0\n",
            "          Dropout-94            [-1, 257, 1536]               0\n",
            "           Linear-95             [-1, 257, 384]               0\n",
            "          Dropout-96             [-1, 257, 384]               0\n",
            "              Mlp-97             [-1, 257, 384]               0\n",
            "       LayerScale-98             [-1, 257, 384]               0\n",
            "NestedTensorBlock-99             [-1, 257, 384]               0\n",
            "       LayerNorm-100             [-1, 257, 384]             768\n",
            "          Linear-101            [-1, 257, 1152]               0\n",
            "         Dropout-102          [-1, 6, 257, 257]               0\n",
            "          Linear-103             [-1, 257, 384]               0\n",
            "         Dropout-104             [-1, 257, 384]               0\n",
            " MemEffAttention-105             [-1, 257, 384]               0\n",
            "      LayerScale-106             [-1, 257, 384]               0\n",
            "       LayerNorm-107             [-1, 257, 384]             768\n",
            "          Linear-108            [-1, 257, 1536]               0\n",
            "            GELU-109            [-1, 257, 1536]               0\n",
            "         Dropout-110            [-1, 257, 1536]               0\n",
            "          Linear-111             [-1, 257, 384]               0\n",
            "         Dropout-112             [-1, 257, 384]               0\n",
            "             Mlp-113             [-1, 257, 384]               0\n",
            "      LayerScale-114             [-1, 257, 384]               0\n",
            "NestedTensorBlock-115             [-1, 257, 384]               0\n",
            "       LayerNorm-116             [-1, 257, 384]             768\n",
            "          Linear-117            [-1, 257, 1152]               0\n",
            "         Dropout-118          [-1, 6, 257, 257]               0\n",
            "          Linear-119             [-1, 257, 384]               0\n",
            "         Dropout-120             [-1, 257, 384]               0\n",
            " MemEffAttention-121             [-1, 257, 384]               0\n",
            "      LayerScale-122             [-1, 257, 384]               0\n",
            "       LayerNorm-123             [-1, 257, 384]             768\n",
            "          Linear-124            [-1, 257, 1536]               0\n",
            "            GELU-125            [-1, 257, 1536]               0\n",
            "         Dropout-126            [-1, 257, 1536]               0\n",
            "          Linear-127             [-1, 257, 384]               0\n",
            "         Dropout-128             [-1, 257, 384]               0\n",
            "             Mlp-129             [-1, 257, 384]               0\n",
            "      LayerScale-130             [-1, 257, 384]               0\n",
            "NestedTensorBlock-131             [-1, 257, 384]               0\n",
            "       LayerNorm-132             [-1, 257, 384]             768\n",
            "          Linear-133            [-1, 257, 1152]               0\n",
            "         Dropout-134          [-1, 6, 257, 257]               0\n",
            "          Linear-135             [-1, 257, 384]               0\n",
            "         Dropout-136             [-1, 257, 384]               0\n",
            " MemEffAttention-137             [-1, 257, 384]               0\n",
            "      LayerScale-138             [-1, 257, 384]               0\n",
            "       LayerNorm-139             [-1, 257, 384]             768\n",
            "          Linear-140            [-1, 257, 1536]               0\n",
            "            GELU-141            [-1, 257, 1536]               0\n",
            "         Dropout-142            [-1, 257, 1536]               0\n",
            "          Linear-143             [-1, 257, 384]               0\n",
            "         Dropout-144             [-1, 257, 384]               0\n",
            "             Mlp-145             [-1, 257, 384]               0\n",
            "      LayerScale-146             [-1, 257, 384]               0\n",
            "NestedTensorBlock-147             [-1, 257, 384]               0\n",
            "       LayerNorm-148             [-1, 257, 384]             768\n",
            "          Linear-149            [-1, 257, 1152]               0\n",
            "         Dropout-150          [-1, 6, 257, 257]               0\n",
            "          Linear-151             [-1, 257, 384]               0\n",
            "         Dropout-152             [-1, 257, 384]               0\n",
            " MemEffAttention-153             [-1, 257, 384]               0\n",
            "      LayerScale-154             [-1, 257, 384]               0\n",
            "       LayerNorm-155             [-1, 257, 384]             768\n",
            "          Linear-156            [-1, 257, 1536]               0\n",
            "            GELU-157            [-1, 257, 1536]               0\n",
            "         Dropout-158            [-1, 257, 1536]               0\n",
            "          Linear-159             [-1, 257, 384]               0\n",
            "         Dropout-160             [-1, 257, 384]               0\n",
            "             Mlp-161             [-1, 257, 384]               0\n",
            "      LayerScale-162             [-1, 257, 384]               0\n",
            "NestedTensorBlock-163             [-1, 257, 384]               0\n",
            "       LayerNorm-164             [-1, 257, 384]             768\n",
            "          Linear-165            [-1, 257, 1152]               0\n",
            "         Dropout-166          [-1, 6, 257, 257]               0\n",
            "          Linear-167             [-1, 257, 384]               0\n",
            "         Dropout-168             [-1, 257, 384]               0\n",
            " MemEffAttention-169             [-1, 257, 384]               0\n",
            "      LayerScale-170             [-1, 257, 384]               0\n",
            "       LayerNorm-171             [-1, 257, 384]             768\n",
            "          Linear-172            [-1, 257, 1536]               0\n",
            "            GELU-173            [-1, 257, 1536]               0\n",
            "         Dropout-174            [-1, 257, 1536]               0\n",
            "          Linear-175             [-1, 257, 384]               0\n",
            "         Dropout-176             [-1, 257, 384]               0\n",
            "             Mlp-177             [-1, 257, 384]               0\n",
            "      LayerScale-178             [-1, 257, 384]               0\n",
            "NestedTensorBlock-179             [-1, 257, 384]               0\n",
            "       LayerNorm-180             [-1, 257, 384]             768\n",
            "          Linear-181            [-1, 257, 1152]               0\n",
            "         Dropout-182          [-1, 6, 257, 257]               0\n",
            "          Linear-183             [-1, 257, 384]               0\n",
            "         Dropout-184             [-1, 257, 384]               0\n",
            " MemEffAttention-185             [-1, 257, 384]               0\n",
            "      LayerScale-186             [-1, 257, 384]               0\n",
            "       LayerNorm-187             [-1, 257, 384]             768\n",
            "          Linear-188            [-1, 257, 1536]               0\n",
            "            GELU-189            [-1, 257, 1536]               0\n",
            "         Dropout-190            [-1, 257, 1536]               0\n",
            "          Linear-191             [-1, 257, 384]               0\n",
            "         Dropout-192             [-1, 257, 384]               0\n",
            "             Mlp-193             [-1, 257, 384]               0\n",
            "      LayerScale-194             [-1, 257, 384]               0\n",
            "NestedTensorBlock-195             [-1, 257, 384]               0\n",
            "       LayerNorm-196             [-1, 257, 384]             768\n",
            "        Identity-197                  [-1, 384]               0\n",
            "DinoVisionTransformer-198                  [-1, 384]               0\n",
            "       LayerNorm-199                  [-1, 384]             768\n",
            "          Linear-200                  [-1, 512]               0\n",
            "            ReLU-201                  [-1, 512]               0\n",
            "         Dropout-202                  [-1, 512]               0\n",
            "          Linear-203                    [-1, 8]               0\n",
            "================================================================\n",
            "Total params: 246,144\n",
            "Trainable params: 246,144\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 274.22\n",
            "Params size (MB): 0.94\n",
            "Estimated Total Size (MB): 275.73\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing Quantized Model: 100%|██████████| 60/60 [19:17<00:00, 19.29s/it, acc=0.6953]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy: 0.6953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(\"Total params for original dinov2:\", count_params(model))\n",
        "print(\"Total params for quantized dinov2:\", count_params(quantized_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b2rAxVSueeT",
        "outputId": "4df457ca-59a7-4bbe-81ab-8fcab2758adb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total params for original dinov2: 22257800\n",
            "Total params for quantized dinov2: 781440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary as info_summary\n",
        "info_summary(model, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhEFwG1K0p4O",
        "outputId": "ba734f39-4464-457b-d0c9-35e007ebbd75"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "DINOv2Classifier                              [1, 8]                    --\n",
              "├─DinoVisionTransformer: 1-1                  [1, 384]                  526,848\n",
              "│    └─PatchEmbed: 2-1                        [1, 256, 384]             --\n",
              "│    │    └─Conv2d: 3-1                       [1, 384, 16, 16]          226,176\n",
              "│    │    └─Identity: 3-2                     [1, 256, 384]             --\n",
              "│    └─ModuleList: 2-2                        --                        --\n",
              "│    │    └─NestedTensorBlock: 3-3            [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-4            [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-5            [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-6            [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-7            [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-8            [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-9            [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-10           [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-11           [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-12           [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-13           [1, 257, 384]             1,775,232\n",
              "│    │    └─NestedTensorBlock: 3-14           [1, 257, 384]             1,775,232\n",
              "│    └─LayerNorm: 2-3                         [1, 257, 384]             768\n",
              "│    └─Identity: 2-4                          [1, 384]                  --\n",
              "│    └─LayerNorm: 2-5                         [1, 384]                  (recursive)\n",
              "├─Sequential: 1-2                             [1, 8]                    --\n",
              "│    └─Linear: 2-6                            [1, 512]                  197,120\n",
              "│    └─ReLU: 2-7                              [1, 512]                  --\n",
              "│    └─Dropout: 2-8                           [1, 512]                  --\n",
              "│    └─Linear: 2-9                            [1, 8]                    4,104\n",
              "===============================================================================================\n",
              "Total params: 22,257,800\n",
              "Trainable params: 22,257,800\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 79.40\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 124.75\n",
              "Params size (MB): 86.92\n",
              "Estimated Total Size (MB): 212.27\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info_summary(quantized_model, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SThZlYZk2YIE",
        "outputId": "1e3b95ba-f2b3-4882-eea3-b1d8948f8834"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "QuantizedDINOv2Classifier                     [1, 8]                    --\n",
              "├─DinoVisionTransformer: 1-1                  [1, 384]                  526,848\n",
              "│    └─PatchEmbed: 2-1                        [1, 256, 384]             --\n",
              "│    │    └─Conv2d: 3-1                       [1, 384, 16, 16]          226,176\n",
              "│    │    └─Identity: 3-2                     [1, 256, 384]             --\n",
              "│    └─ModuleList: 2-2                        --                        --\n",
              "│    │    └─NestedTensorBlock: 3-3            [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-4            [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-5            [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-6            [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-7            [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-8            [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-9            [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-10           [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-11           [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-12           [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-13           [1, 257, 384]             2,304\n",
              "│    │    └─NestedTensorBlock: 3-14           [1, 257, 384]             2,304\n",
              "│    └─LayerNorm: 2-3                         [1, 257, 384]             768\n",
              "│    └─Identity: 2-4                          [1, 384]                  --\n",
              "│    └─LayerNorm: 2-5                         [1, 384]                  (recursive)\n",
              "├─Sequential: 1-2                             [1, 8]                    --\n",
              "│    └─Linear: 2-6                            [1, 512]                  --\n",
              "│    └─ReLU: 2-7                              [1, 512]                  --\n",
              "│    └─Dropout: 2-8                           [1, 512]                  --\n",
              "│    └─Linear: 2-9                            [1, 8]                    --\n",
              "===============================================================================================\n",
              "Total params: 781,440\n",
              "Trainable params: 781,440\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 57.92\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 39.48\n",
              "Params size (MB): 1.02\n",
              "Estimated Total Size (MB): 41.10\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post Training Static Quantization"
      ],
      "metadata": {
        "id": "FJeG-LhkgZa4"
      }
    }
  ]
}