{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.jit import trace\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "LR_HEAD = 1e-3\n",
    "LR_BACKBONE = 1e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS_LP = 10\n",
    "EPOCHS_FT = 8\n",
    "UNFREEZE_BLOCKS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_csv = \"/home/zack/11785/project/data/HAM10000_dataset/HAM10000_metadata.csv\"\n",
    "img_dir  = \"/home/zack/11785/project/data/HAM10000_dataset\"\n",
    "\n",
    "df = pd.read_csv(meta_csv)\n",
    "df['image_id'] = df['image_id'].apply(lambda x: f\"{x}.jpg\")\n",
    "df = df[df['dx'].notna()]\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df['dx'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(self.df['dx'].unique())\n",
    "        self.class_to_idx = {c:i for i,c in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = os.path.join(self.img_dir, row['image_id'])\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.class_to_idx[row['dx']]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = HAM10000Dataset(train_df, img_dir, transform=train_tfms)\n",
    "t_val   = HAM10000Dataset(val_df,   img_dir, transform=val_tfms)\n",
    "train_loader = DataLoader(t_train, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS)\n",
    "val_loader   = DataLoader(t_val,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "NUM_CLASSES = len(t_train.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\").to(device)\n",
    "feat_dim = backbone.embed_dim\n",
    "num_blocks = len(backbone.blocks)\n",
    "\n",
    "head = nn.Linear(feat_dim, NUM_CLASSES).to(device)\n",
    "\n",
    "class DinoClassifier(nn.Module):\n",
    "    def __init__(self, backbone, head):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.head = head\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        return self.head(feats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for x, y in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "def measure_inference_time(model, device, runs=100):\n",
    "    model.eval()\n",
    "    example = torch.randn(1,3,224,224).to(device)\n",
    "    for _ in range(10): _ = model(example)\n",
    "    torch.cuda.synchronize()\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end   = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    for _ in range(runs): _ = model(example)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return start.elapsed_time(end) / runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Linear Probing ==========\n",
    "\n",
    "for p in backbone.parameters(): p.requires_grad = False\n",
    "for p in head.parameters():    p.requires_grad = True\n",
    "model_lp = DinoClassifier(backbone, head).to(device)\n",
    "optimizer_lp = optim.AdamW(head.parameters(), lr=LR_HEAD, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"=== Linear Probing Training ===\")\n",
    "for epoch in range(EPOCHS_LP):\n",
    "    loss = train_epoch(model_lp, train_loader, optimizer_lp, criterion, device)\n",
    "    acc  = evaluate(model_lp, val_loader, device)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS_LP} — loss: {loss:.4f}, val_acc: {acc:.4%}\")\n",
    "acc_lp  = evaluate(model_lp, val_loader, device)\n",
    "time_lp = measure_inference_time(model_lp, device)\n",
    "torch.jit.trace(model_lp.eval(), torch.randn(1,3,224,224).to(device)).save(\"model_lp.ts\")\n",
    "size_lp = os.path.getsize(\"model_lp.ts\")/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Partial Fine-tuning ==========\n",
    "for p in backbone.parameters():  p.requires_grad = False\n",
    "for blk in backbone.blocks[-UNFREEZE_BLOCKS:]:\n",
    "    for p in blk.parameters(): p.requires_grad = True\n",
    "for p in head.parameters(): p.requires_grad = True\n",
    "params_ft = [\n",
    "    {\"params\": head.parameters(),                             \"lr\": LR_HEAD},\n",
    "    {\"params\": [p for p in backbone.parameters() if p.requires_grad], \"lr\": LR_BACKBONE},\n",
    "]\n",
    "optimizer_ft = optim.AdamW(params_ft, weight_decay=WEIGHT_DECAY)\n",
    "print(\"=== Partial Fine-tuning ===\")\n",
    "for epoch in range(EPOCHS_FT):\n",
    "    loss = train_epoch(model_lp, train_loader, optimizer_ft, criterion, device)\n",
    "    acc  = evaluate(model_lp, val_loader, device)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS_FT} — loss: {loss:.4f}, val_acc: {acc:.4%}\")\n",
    "acc_ft  = evaluate(model_lp, val_loader, device)\n",
    "time_ft = measure_inference_time(model_lp, device)\n",
    "model_ft = torch.jit.trace(model_lp.eval(), torch.randn(1,3,224,224).to(device))\n",
    "model_ft.save(\"model_ft.ts\")\n",
    "size_ft = os.path.getsize(\"model_ft.ts\")/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== ONNX + INT8 Quantization ==========\n",
    "import torch\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_ft = torch.jit.load(\"model_ft.ts\", map_location='cpu')\n",
    "model_ft.eval()\n",
    "\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "onnx_path = \"model_ft.onnx\"\n",
    "\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_ft,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=13,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "class CalibrationDataset:\n",
    "    def __init__(self, dataloader, max_samples=100):\n",
    "        self.dataloader = dataloader\n",
    "        self.max_samples = max_samples\n",
    "        self.current_sample = 0\n",
    "        self.batches = []\n",
    "        \n",
    "        for x, _ in tqdm(dataloader, total=min(max_samples, len(dataloader))):\n",
    "            self.batches.append(x.numpy())\n",
    "            self.current_sample += 1\n",
    "            if self.current_sample >= self.max_samples:\n",
    "                break\n",
    "        self.current_sample = 0\n",
    "        \n",
    "    def get_batch(self):\n",
    "        if self.current_sample >= len(self.batches):\n",
    "            return None\n",
    "        batch = self.batches[self.current_sample]\n",
    "        self.current_sample += 1\n",
    "        return batch\n",
    "\n",
    "class Int8Calibrator(trt.IInt8EntropyCalibrator2):\n",
    "    def __init__(self, dataset, cache_file=\"calibration.cache\"):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.cache_file = cache_file\n",
    "        self.device_input = None\n",
    "        \n",
    "    def get_batch_size(self):\n",
    "        return BATCH_SIZE\n",
    "    \n",
    "    def get_batch(self, names):\n",
    "        batch = self.dataset.get_batch()\n",
    "        if batch is None:\n",
    "            return None\n",
    "            \n",
    "        if self.device_input is None:\n",
    "            self.device_input = cuda.mem_alloc(batch.nbytes)\n",
    "        \n",
    "        cuda.memcpy_htod(self.device_input, batch)\n",
    "        return [int(self.device_input)]\n",
    "    \n",
    "    def read_calibration_cache(self):\n",
    "        if os.path.exists(self.cache_file):\n",
    "            with open(self.cache_file, \"rb\") as f:\n",
    "                return f.read()\n",
    "        return None\n",
    "        \n",
    "    def write_calibration_cache(self, cache):\n",
    "        with open(self.cache_file, \"wb\") as f:\n",
    "            f.write(cache)\n",
    "\n",
    "# 4. TensorRT \n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def build_trt_engine_int8(onnx_file_path):\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    \n",
    "    with open(onnx_file_path, 'rb') as model:\n",
    "        if not parser.parse(model.read()):\n",
    "            print(\"ERROR: Failed to parse the ONNX file.\")\n",
    "            for error in range(parser.num_errors):\n",
    "                print(parser.get_error(error))\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    config = builder.create_builder_config()\n",
    "    config.max_workspace_size = 1 << 30  # 1GB\n",
    "    config.set_flag(trt.BuilderFlag.INT8)\n",
    "    \n",
    "\n",
    "    calibration_dataset = CalibrationDataset(val_loader)\n",
    "    calibrator = Int8Calibrator(calibration_dataset)\n",
    "    config.int8_calibrator = calibrator\n",
    "    \n",
    "\n",
    "    profile = builder.create_optimization_profile()\n",
    "    profile.set_shape(\"input\", (1, 3, 224, 224), (BATCH_SIZE, 3, 224, 224), (BATCH_SIZE*2, 3, 224, 224))\n",
    "    config.add_optimization_profile(profile)\n",
    "    \n",
    "    engine = builder.build_engine(network, config)\n",
    "    \n",
    "    with open(\"model_ft_trt_int8.engine\", \"wb\") as f:\n",
    "        f.write(engine.serialize())\n",
    "    \n",
    "    return engine\n",
    "\n",
    "engine = build_trt_engine_int8(onnx_path)\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "def load_engine(engine_path):\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        return runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "def allocate_buffers(engine, batch_size=1):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    bindings = []\n",
    "    stream = cuda.Stream()\n",
    "    \n",
    "    for binding in engine:\n",
    "        dims = engine.get_binding_shape(binding)\n",
    "        if dims[0] == -1: \n",
    "            dims[0] = batch_size\n",
    "        size = trt.volume(dims) * engine.max_batch_size\n",
    "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "        \n",
    "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "        \n",
    "        bindings.append(int(device_mem))\n",
    "        \n",
    "        if engine.binding_is_input(binding):\n",
    "            inputs.append({\"host\": host_mem, \"device\": device_mem, \"name\": binding})\n",
    "        else:\n",
    "            outputs.append({\"host\": host_mem, \"device\": device_mem, \"name\": binding})\n",
    "    \n",
    "    return inputs, outputs, bindings, stream\n",
    "\n",
    "def infer_trt(context, bindings, inputs, outputs, stream, batch_size=1):\n",
    "\n",
    "    for inp in inputs:\n",
    "        cuda.memcpy_htod_async(inp[\"device\"], inp[\"host\"], stream)\n",
    "    \n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "\n",
    "    for out in outputs:\n",
    "        cuda.memcpy_dtoh_async(out[\"host\"], out[\"device\"], stream)\n",
    "    \n",
    "    stream.synchronize()\n",
    "    \n",
    "    return [out[\"host\"] for out in outputs]\n",
    "\n",
    "\n",
    "engine = load_engine(\"model_ft_trt_int8.engine\")\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "\n",
    "inputs, outputs, bindings, stream = allocate_buffers(engine)\n",
    "\n",
    "def measure_inference_time_trt(context, inputs, outputs, bindings, stream, runs=100):\n",
    "\n",
    "    dummy_input = np.random.rand(1, 3, 224, 224).astype(np.float32)\n",
    "    inputs[0][\"host\"] = np.ascontiguousarray(dummy_input)\n",
    "    \n",
    "    for _ in range(10):\n",
    "        infer_trt(context, bindings, inputs, outputs, stream)\n",
    "    \n",
    "    start = time.time()\n",
    "    for _ in range(runs):\n",
    "        infer_trt(context, bindings, inputs, outputs, stream)\n",
    "    end = time.time()\n",
    "    \n",
    "    return (end - start) * 1000 / runs  \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_trt(engine, val_loader, device):\n",
    "    context = engine.create_execution_context()\n",
    "    inputs, outputs, bindings, stream = allocate_buffers(engine)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for x, y in tqdm(val_loader, desc=\"评估TensorRT\"):\n",
    "        batch_size = x.shape[0]\n",
    "        x_np = x.cpu().numpy()\n",
    "        \n",
    "        inputs[0][\"host\"] = np.ascontiguousarray(x_np)\n",
    "\n",
    "        context.set_binding_shape(0, (batch_size, 3, 224, 224))\n",
    "        \n",
    "        output = infer_trt(context, bindings, inputs, outputs, stream, batch_size)\n",
    "        \n",
    "        logits = output[0].reshape(batch_size, NUM_CLASSES)\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        \n",
    "        correct += (pred == y.cpu().numpy()).sum()\n",
    "        total += batch_size\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "time_qt = measure_inference_time_trt(context, inputs, outputs, bindings, stream)\n",
    "acc_qt = evaluate_trt(engine, val_loader, device)\n",
    "size_qt = os.path.getsize(\"model_ft_trt_int8.engine\") / 1e6  # MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Results Comparison ===\")\n",
    "print(f\"{'Scheme':<40} {'Top1 Acc':>10}   {'Infer(ms)':>10}   {'Size(MB)':>8}\")\n",
    "print(\"-\"*68)\n",
    "print(f\"{'1. Linear Probing':<40} {acc_lp*100:>9.2f}%   {time_lp:>10.2f}   {size_lp:>8.2f}\")\n",
    "print(f\"{'2. Linear + Partial FT':<40} {acc_ft*100:>9.2f}%   {time_ft:>10.2f}   {size_ft:>8.2f}\")\n",
    "print(f\"{'3. INT8 Quantization':<40} {acc_qt*100:>9.2f}%   {time_qt:>10.2f}   {size_qt:>8.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "785project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
